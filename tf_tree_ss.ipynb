{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Active Learning for IC design by Ashish James, July 20, 2018\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import time\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from modAL.uncertainty import uncertainty_sampling\n",
    "from modAL.models import ActiveLearner, Committee\n",
    "\n",
    "##from models.model_clf import IC_Design_DNN_Clf\n",
    "\n",
    "scaler = StandardScaler()\n",
    "num_classes = 2\n",
    "REG_FLAG = False\n",
    "csv_file = \"circuit-design/opAmp_280nm_GF55_Mod_30P.csv\"  # Dataset1\n",
    "input_dims = 9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class IC_Design_DNN_Clf:\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def __call__(self, X, reuse=False):\n",
    "\n",
    "        with tf.variable_scope(self.name) as scope:\n",
    "\n",
    "            if reuse:\n",
    "                scope.reuse_variables()\n",
    "\n",
    "            dense1 = tf.layers.dense(inputs=X, units=64, activation=tf.nn.relu)\n",
    "            dense2 = tf.layers.dense(inputs=dense1, units=64, activation=tf.nn.relu)\n",
    "            # dense3 = tf.layers.dense(inputs=dense2, units=64, activation=tf.nn.relu)\n",
    "            outputs = tf.layers.dense(inputs=dense2, units=2, activation=tf.nn.relu)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    @property\n",
    "    def vars(self):\n",
    "        return tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=self.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gregoire/anaconda3/envs/pytorch_fury/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/gregoire/anaconda3/envs/pytorch_fury/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def read_data(csv_file):\n",
    "    data = pd.read_csv(csv_file)\n",
    "    input = data.iloc[:,0:9]    \n",
    "    if REG_FLAG:\n",
    "        output = data.iloc[:,10:17]        \n",
    "    else:\n",
    "        output = data.iloc[:,9]\n",
    "        integer_encoded = LabelEncoder().fit_transform(output)\n",
    "        output = to_categorical(integer_encoded)\n",
    "    return input, output\n",
    "input, output = read_data(csv_file)\n",
    "\n",
    "#logdir = 'tf_logs/Inverse_Prob'\n",
    "#ckptdir = logdir + '/model'\n",
    "#if not os.path.exists(logdir):\n",
    "#    os.mkdir(logdir)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.random.set_random_seed(1)\n",
    "\n",
    "with tf.name_scope('Classifier'):\n",
    "    # Initialize neural network\n",
    "    DNN = IC_Design_DNN_Clf('DNN')\n",
    "    # Setup training process\n",
    "    lmda = tf.placeholder_with_default(0.01, shape=[], name='lambda')\n",
    "    X = tf.placeholder(tf.float32, [None, 9], name='X')\n",
    "    Y = tf.placeholder(tf.float32, [None, 2], name='Y')\n",
    "\n",
    "    tf.add_to_collection('placeholders', lmda)\n",
    "\n",
    "    Targets = DNN(X)\n",
    "    Targets_s = tf.nn.sigmoid(Targets)\n",
    "\n",
    "    # cost = tf.reduce_mean(tf.square(Targets-Y))\n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Targets, labels=Y))\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost, var_list=DNN.vars)\n",
    "\n",
    "    # correct_prediction = Targets - Y\n",
    "    correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Targets_s, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    err_rate = 1 - accuracy\n",
    "\n",
    "cost_summary = tf.summary.scalar('Cost', cost)\n",
    "accuray_summary = tf.summary.scalar('Accuracy', accuracy)\n",
    "summary = tf.summary.merge_all()\n",
    "input_norm = scaler.fit_transform(input)\n",
    "scl_mean_ip = scaler.mean_\n",
    "scl_var_ip = scaler.var_\n",
    "# trainY = output #scaler.fit_transform(output)\n",
    "# scl_mean_op = scaler.mean_\n",
    "# scl_var_op = scaler.var_\n",
    "# Train, test and validation datasets\n",
    "trainX_tmp, testX, trainY_tmp, testY  = train_test_split(input_norm, output, test_size=0.2, random_state=1)\n",
    "trainX_tmp, valX, trainY_tmp, valY = train_test_split(trainX_tmp, trainY_tmp, test_size=0.25, random_state=1)\n",
    "\n",
    "sel_rate = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random\n",
      "0.030053377151489258\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "start = time.time()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#saver = tf.train.Saver()\n",
    "#file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "\n",
    "sel_met = 'random'\n",
    "#sel_met = 'active'\n",
    "\n",
    "print (sel_met)\n",
    "       # -----------------------------------\n",
    "if sel_met == 'random':\n",
    "    # --------------------------------------------------------------\n",
    "    # No.1 Randomly select the train samples\n",
    "    trainY_tmp_lab = np.argmax(trainY_tmp, axis=1)\n",
    "    fail_ind = np.argwhere(trainY_tmp_lab == 0)[:,0]\n",
    "    pass_ind = np.argwhere(trainY_tmp_lab == 1)[:,0]\n",
    "\n",
    "    trainX_fail_tmp = trainX_tmp[fail_ind]\n",
    "    trainY_fail_tmp = trainY_tmp[fail_ind]\n",
    "    trainX_pass_tmp = trainX_tmp[pass_ind]\n",
    "    trainY_pass_tmp = trainY_tmp[pass_ind]\n",
    "\n",
    "    fail_ran = np.random.permutation(fail_ind.shape[0])\n",
    "    fail_sel = fail_ran[np.arange(0, np.int(np.dot(fail_ind.shape[0], sel_rate)), 1)]\n",
    "    pass_ran = np.random.permutation(pass_ind.shape[0])\n",
    "    pass_sel = pass_ran[np.arange(0, np.int(np.dot(pass_ind.shape[0], sel_rate)), 1)]\n",
    "\n",
    "    trainX_pass = trainX_pass_tmp[pass_sel]\n",
    "    trainY_pass = trainY_pass_tmp[pass_sel]\n",
    "    trainX_fail = trainX_fail_tmp[fail_sel]\n",
    "    trainY_fail = trainY_fail_tmp[fail_sel]\n",
    "\n",
    "    trainX = np.vstack((trainX_pass, trainX_fail))\n",
    "    trainY = np.vstack((trainY_pass, trainY_fail))\n",
    "\n",
    "else :\n",
    "    #---------------------------------------------------\n",
    "    #active learning  \n",
    "    #import pdb; pdb.set_trace()\n",
    "    n_members = 2\n",
    "    learner_list = list()\n",
    "\n",
    "    for member_idx in range(n_members):\n",
    "        # initial training data\n",
    "        n_initial = 2\n",
    "        initial_idx = np.random.choice(range(trainX_tmp.shape[0]), size=n_initial, replace=False)\n",
    "        trainX_initial = trainX_tmp[initial_idx]\n",
    "        trainY_initial = trainY_tmp[initial_idx][:,0]\n",
    "\n",
    "        trainX_pool = np.delete(trainX_tmp, initial_idx, axis = 0)\n",
    "        trainY_pool = np.delete(trainY_tmp[:,0], initial_idx)\n",
    "        trainY_pool_org = np.delete(trainY_tmp, initial_idx, axis = 0)\n",
    "\n",
    "        # initializing the active learner\n",
    "        learner = ActiveLearner(\n",
    "            estimator = RandomForestClassifier(),\n",
    "            # query_strategy = uncertainty_sampling,   \n",
    "            X_training = trainX_initial, y_training = trainY_initial\n",
    "            )\n",
    "        \n",
    "        learner_list.append(learner)\n",
    "\n",
    "    committee = Committee(learner_list = learner_list)\n",
    "\n",
    "    # unqueried_score = committee.score(trainX_tmp,trainY_tmp[:,0])\n",
    "    # performance_history = [unqueried_score]\n",
    "    # active learning\n",
    "    n_queries = np.int(np.dot(trainX_tmp.shape[0], sel_rate)) - n_initial\n",
    "\n",
    "    trainX = np.zeros(shape = (n_queries, 9))\n",
    "    trainY = np.zeros(shape = (n_queries, 2))\n",
    "    for idx in range(n_queries):\n",
    "        query_idx, query_instance = committee.query(trainX_pool)  \n",
    "        #print(query_idx)\n",
    "\n",
    "        committee.teach(trainX_pool[query_idx].reshape(1,-1), trainY_pool[query_idx]) \n",
    "        # performance_history.append(committee.score(trainX_tmp, trainY_tmp[:,0]))\n",
    "        trainX[idx] = trainX_pool[query_idx]\n",
    "        trainY[idx] = trainY_pool_org[query_idx]\n",
    "        trainX_pool, trainY_pool, trainY_pool_org = np.delete(trainX_pool, query_idx, axis = 0), np.delete(trainY_pool, query_idx, axis = 0), np.delete(trainY_pool_org, query_idx, axis = 0)\n",
    "# --------------------------------------------------------------------------------\n",
    "end = time.time()\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Tsize = 414 cost = 0.719568262 acc = 0.681159423 err_r = 0.279103398\n",
      "Epoch: 0002 Tsize = 414 cost = 0.689282590 acc = 0.753623194 err_r = 0.233550251\n",
      "Epoch: 0003 Tsize = 414 cost = 0.662135918 acc = 0.797101455 err_r = 0.265365124\n",
      "Epoch: 0004 Tsize = 414 cost = 0.540087604 acc = 0.826086961 err_r = 0.255965292\n",
      "Epoch: 0005 Tsize = 414 cost = 0.549489423 acc = 0.838164257 err_r = 0.214027464\n",
      "Epoch: 0006 Tsize = 414 cost = 0.512767061 acc = 0.864734305 err_r = 0.204627633\n",
      "Epoch: 0007 Tsize = 414 cost = 0.495457579 acc = 0.869565223 err_r = 0.194504678\n",
      "Epoch: 0008 Tsize = 414 cost = 0.477708899 acc = 0.876811599 err_r = 0.185827911\n",
      "Epoch: 0009 Tsize = 414 cost = 0.465165907 acc = 0.893719811 err_r = 0.179320335\n",
      "Epoch: 0010 Tsize = 414 cost = 0.457468842 acc = 0.900966188 err_r = 0.174258828\n",
      "Epoch: 0011 Tsize = 414 cost = 0.449792461 acc = 0.908212565 err_r = 0.168474317\n",
      "Epoch: 0012 Tsize = 414 cost = 0.441736634 acc = 0.915458941 err_r = 0.161243677\n",
      "Epoch: 0013 Tsize = 414 cost = 0.431954322 acc = 0.917874400 err_r = 0.156182230\n",
      "Epoch: 0014 Tsize = 414 cost = 0.424872258 acc = 0.920289859 err_r = 0.156182230\n",
      "Epoch: 0015 Tsize = 414 cost = 0.417698346 acc = 0.929951694 err_r = 0.152566910\n",
      "Epoch: 0016 Tsize = 414 cost = 0.413234318 acc = 0.934782612 err_r = 0.148951530\n",
      "Epoch: 0017 Tsize = 414 cost = 0.404712329 acc = 0.949275364 err_r = 0.140997827\n",
      "Epoch: 0018 Tsize = 414 cost = 0.396766620 acc = 0.958937200 err_r = 0.138105571\n",
      "Epoch: 0019 Tsize = 414 cost = 0.395779355 acc = 0.961352659 err_r = 0.133044124\n",
      "Epoch: 0020 Tsize = 414 cost = 0.389816894 acc = 0.966183576 err_r = 0.134490252\n",
      "Epoch: 0021 Tsize = 414 cost = 0.386526353 acc = 0.975845412 err_r = 0.127982676\n",
      "Epoch: 0022 Tsize = 414 cost = 0.383163147 acc = 0.975845412 err_r = 0.119305849\n",
      "Epoch: 0023 Tsize = 414 cost = 0.381169586 acc = 0.975845412 err_r = 0.116413593\n",
      "Epoch: 0024 Tsize = 414 cost = 0.374519319 acc = 0.983091788 err_r = 0.122198105\n",
      "Epoch: 0025 Tsize = 414 cost = 0.374746821 acc = 0.987922706 err_r = 0.116413593\n",
      "Epoch: 0026 Tsize = 414 cost = 0.372028435 acc = 0.987922706 err_r = 0.112075210\n",
      "Epoch: 0027 Tsize = 414 cost = 0.367530464 acc = 0.992753624 err_r = 0.107736826\n",
      "Epoch: 0028 Tsize = 414 cost = 0.366429740 acc = 0.995169082 err_r = 0.105567634\n",
      "Epoch: 0029 Tsize = 414 cost = 0.362283406 acc = 0.995169082 err_r = 0.112798274\n",
      "Epoch: 0030 Tsize = 414 cost = 0.363076478 acc = 0.995169082 err_r = 0.109182954\n",
      "Epoch: 0031 Tsize = 414 cost = 0.360511804 acc = 0.995169082 err_r = 0.110629082\n",
      "Epoch: 0032 Tsize = 414 cost = 0.360472207 acc = 0.995169082 err_r = 0.107013762\n",
      "Epoch: 0033 Tsize = 414 cost = 0.358135166 acc = 0.995169082 err_r = 0.112075210\n",
      "Epoch: 0034 Tsize = 414 cost = 0.358361926 acc = 0.995169082 err_r = 0.107013762\n",
      "Epoch: 0035 Tsize = 414 cost = 0.356149769 acc = 0.995169082 err_r = 0.107736826\n",
      "Epoch: 0036 Tsize = 414 cost = 0.360364302 acc = 0.992753624 err_r = 0.112075210\n",
      "Epoch: 0037 Tsize = 414 cost = 0.358593107 acc = 0.995169082 err_r = 0.110629082\n",
      "Epoch: 0038 Tsize = 414 cost = 0.356630474 acc = 0.995169082 err_r = 0.115690529\n",
      "Epoch: 0039 Tsize = 414 cost = 0.354181998 acc = 0.995169082 err_r = 0.113521338\n",
      "Epoch: 0040 Tsize = 414 cost = 0.353086704 acc = 0.995169082 err_r = 0.106290698\n",
      "Epoch: 0041 Tsize = 414 cost = 0.355339574 acc = 0.992753624 err_r = 0.113521338\n",
      "Epoch: 0042 Tsize = 414 cost = 0.353534572 acc = 0.995169082 err_r = 0.115690529\n",
      "Epoch: 0043 Tsize = 414 cost = 0.351671092 acc = 0.997584541 err_r = 0.114244401\n",
      "Epoch: 0044 Tsize = 414 cost = 0.351448155 acc = 0.995169082 err_r = 0.112075210\n",
      "Epoch: 0045 Tsize = 414 cost = 0.352096116 acc = 0.997584541 err_r = 0.109182954\n",
      "Epoch: 0046 Tsize = 414 cost = 0.351709182 acc = 0.997584541 err_r = 0.109906018\n",
      "Epoch: 0047 Tsize = 414 cost = 0.350607288 acc = 0.995169082 err_r = 0.110629082\n",
      "Epoch: 0048 Tsize = 414 cost = 0.351660582 acc = 0.997584541 err_r = 0.109906018\n",
      "Epoch: 0049 Tsize = 414 cost = 0.350456043 acc = 1.000000000 err_r = 0.114244401\n",
      "Epoch: 0050 Tsize = 414 cost = 0.353162092 acc = 0.997584541 err_r = 0.107736826\n",
      "Accuracy_Test = 0.871294260\n",
      "24.85584783554077\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "training_epochs = 50\n",
    "batch_size = 3\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    total_batch = int(trainX.shape[0] / batch_size)\n",
    "    \n",
    "    avg_cost = 0\n",
    "    avg_acc = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        ran_from = i * batch_size\n",
    "        ran_to = (i + 1) * batch_size\n",
    "        batch_xs = trainX[ran_from:ran_to]\n",
    "        batch_ys = trainY[ran_from:ran_to]\n",
    "        batch_ys = np.reshape(batch_ys, [batch_size, 2])\n",
    "        # batch_ys = batch_ys.values.reshape(batch_size, 1)\n",
    "        _, cc, aa, summary_str, tt, yy = sess.run([optimizer, cost, accuracy, summary, Targets, Y], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        \n",
    "        avg_cost += cc / total_batch\n",
    "        avg_acc += aa / total_batch\n",
    "\n",
    "        #file_writer.add_summary(summary_str, epoch * total_batch + i)\n",
    "\n",
    "    err_rate_val = sess.run(err_rate, feed_dict={X: valX, Y: valY})\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'Tsize =', '%d' % trainX.shape[0], 'cost =', '{:.9f}'.format(avg_cost), 'acc =', '{:.9f}'.format(avg_acc), 'err_r =', '{:.9f}'.format(err_rate_val),)\n",
    "\n",
    "acc_test = sess.run(accuracy, feed_dict={X: testX, Y: testY})\n",
    "print('Accuracy_Test =', '{:.9f}'.format(acc_test))\n",
    "    # saver.save(sess, ckptdir)\n",
    "\n",
    "sess.close()\n",
    "\n",
    "end = time.time()\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
