{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from vogn import VOGN\n",
    "from models import SimpleConvNet\n",
    "from datasets import Dataset\n",
    "from utils import train_model\n",
    "from utils import inference\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "sns.set()\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : attention aux colums de file_A et file, columns en plus etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Cuda: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9b95017b70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Test wether GPUs are available\n",
    "use_cuda =  torch.cuda.is_available()\n",
    "print(\"Using Cuda: %s\" % use_cuda)\n",
    "\n",
    "# Set Random Seed\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class csvDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, data,label, transform=None):\n",
    "        \n",
    "        self.label = label\n",
    "                \n",
    "        self.data = data\n",
    "         \n",
    "        #self.train_set = TensorDataset()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        data = self.data[idx]\n",
    "        label = self.label[idx]\n",
    "        sample = { 'data': data,'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "    \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        \n",
    "        data, label  = sample['data'],sample['label']\n",
    "        \n",
    "        \n",
    "        return {'data': torch.from_numpy(data).float(),\n",
    "                'label': torch.from_numpy(label).float()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(type(self), self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(16, 64)\n",
    "        self.layer2 = nn.Linear(64, 256)\n",
    "        self.layer3 = nn.Linear(256, 64)\n",
    "        self.layer4 = nn.Linear(64, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.relu(self.layer3(x))\n",
    "        out = self.layer4(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_A=pd.read_csv('circuit-design/opAmp_280nm_GF55.csv')\n",
    "file = pd.read_csv('circuit-design/opAmp_280nm_GF55_Mod_30P.csv')\n",
    "        \n",
    "a=['Pass/Fail']\n",
    "\n",
    "label = np.array(file[a].values=='Fail')*(-1.)+1\n",
    "\n",
    "a = []\n",
    "\n",
    "for i in list(file_A.columns):\n",
    "    if i != 'Pass/Fail':\n",
    "        a.append(i)\n",
    "\n",
    "data = np.array(file[a].values)\n",
    "for i in range(16):\n",
    "    data[:,i]=(data[:,i] - data[:,i].mean())/(data[:,i].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_tmp, testX, trainY_tmp, testY  = train_test_split(data, label, test_size=0.2, random_state=1)\n",
    "trainX_tmp, valX, trainY_tmp, valY = train_test_split(trainX_tmp, trainY_tmp, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6912, 16), (6912, 1))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate((trainX_tmp,valX,testX),axis=0)\n",
    "Y = np.concatenate((trainY_tmp,valY,testY),axis=0)\n",
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6912"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4146+1383+1383"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dataset = csvDataset(X,Y,transform= ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_loader = torch.utils.data.DataLoader(file_dataset,batch_size=43, shuffle=True)\n",
    "dataset_loader = torch.utils.data.DataLoader(file_dataset,\n",
    "                                             batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_loader = torch.utils.data.DataLoader(file_dataset,\n",
    "                                             batch_size=6912, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_bb(liste,model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    \"\"\"\n",
    "    Performs Training and Validation on test set on the given model using the specified optimizer\n",
    "    :param model: (nn.Module) Model to be trained\n",
    "    :param dataloaders: (list) train and test dataloaders\n",
    "    :param criterion: Loss Function\n",
    "    :param optimizer: Optimizer to be used for training\n",
    "    :param num_epochs: Number of epochs to train the model\n",
    "    :return: trained model, test and train metric history\n",
    "    \"\"\"\n",
    "    trainloader, testloader = dataloaders\n",
    "    for epoch in range(num_epochs):\n",
    "        listee = liste.copy()\n",
    "        d = listee.pop()\n",
    "        model.train(True)\n",
    "        print('Epoch[%d]:' % epoch)\n",
    "        running_train_loss = 0.\n",
    "        a=-1\n",
    "        for i in (trainloader):\n",
    "            a+=1\n",
    "            if (a==d):\n",
    "                inputs = i['data']\n",
    "                labels = i['label']\n",
    "                if use_cuda:\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                if isinstance(optimizer, VOGN):\n",
    "                    def closure():\n",
    "                        optimizer.zero_grad()\n",
    "                        logits = model.forward(inputs)\n",
    "                        loss = criterion(logits, labels)\n",
    "                        return loss\n",
    "                else:\n",
    "                    def closure():\n",
    "                        optimizer.zero_grad()\n",
    "                        logits = model.forward(inputs)\n",
    "                        loss = criterion(logits, labels)\n",
    "                        loss.backward()\n",
    "                        return loss\n",
    "                loss = optimizer.step(closure)\n",
    "                running_train_loss += loss.detach().item()\n",
    "                if len(listee)!=0:\n",
    "                    d = listee.pop()\n",
    "                else :\n",
    "                    break\n",
    "\n",
    "            # Print Training Progress\n",
    "            if a%500 == 100:\n",
    "                train_accuracy = accuracy_bb(model, trainloader)\n",
    "                print('Iteration[%d]:  Train Accuracy: %f ' % (a+1, train_accuracy))\n",
    "\n",
    "        train_accuracy, train_loss = accuracy_bb(model, trainloader, criterion)\n",
    "        print('## Epoch[%d], Train Loss: %f   &   Train Accuracy: %f' % (epoch, train_loss, train_accuracy))\n",
    "    return model, train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_cc(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    \"\"\"\n",
    "    Performs Training and Validation on test set on the given model using the specified optimizer\n",
    "    :param model: (nn.Module) Model to be trained\n",
    "    :param dataloaders: (list) train and test dataloaders\n",
    "    :param criterion: Loss Function\n",
    "    :param optimizer: Optimizer to be used for training\n",
    "    :param num_epochs: Number of epochs to train the model\n",
    "    :return: trained model, test and train metric history\n",
    "    \"\"\"\n",
    "    trainloader, testloader = dataloaders\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train(True)\n",
    "        print('Epoch[%d]:' % epoch)\n",
    "        running_train_loss = 0.\n",
    "        a=-1\n",
    "        for i in (trainloader):\n",
    "            a+=1\n",
    "            inputs = i['data']\n",
    "            labels = i['label']\n",
    "            if use_cuda:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            if isinstance(optimizer, VOGN):\n",
    "                def closure():\n",
    "                    optimizer.zero_grad()\n",
    "                    logits = model.forward(inputs)\n",
    "                    loss = criterion(logits, labels)\n",
    "                    return loss\n",
    "            else:\n",
    "                def closure():\n",
    "                    optimizer.zero_grad()\n",
    "                    logits = model.forward(inputs)\n",
    "                    loss = criterion(logits, labels)\n",
    "                    loss.backward()\n",
    "                    return loss\n",
    "            loss = optimizer.step(closure)\n",
    "            running_train_loss += loss.detach().item()\n",
    "\n",
    "\n",
    "            # Print Training Progress\n",
    "            if a%500 == 100:\n",
    "                train_accuracy = accuracy_bb(model, trainloader)\n",
    "                print('Iteration[%d]:  Train Accuracy: %f ' % (a+1, train_accuracy))\n",
    "\n",
    "        train_accuracy, train_loss = accuracy_bb(model, trainloader, criterion)\n",
    "        print('## Epoch[%d], Train Loss: %f   &   Train Accuracy: %f' % (epoch, train_loss, train_accuracy))\n",
    "    return model, train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_bb(model, dataloader, criterion=None):\n",
    "    \"\"\" Computes the model's classification accuracy on the train dataset\n",
    "        Computes classification accuracy and loss(optional) on the test dataset\n",
    "        The model should return logits\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0.\n",
    "        running_loss = 0.\n",
    "        for i in (dataloader):\n",
    "            inputs = i['data']\n",
    "            labels = i['label']\n",
    "            if use_cuda:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            if criterion is not None:\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item()\n",
    "            pred = (outputs>0).float()\n",
    "            correct += (pred.view(-1,1) == labels).sum().item()\n",
    "        accuracy = correct / len(dataloader.dataset)\n",
    "        if criterion is not None:\n",
    "            running_loss = running_loss / len(dataloader)\n",
    "            return accuracy, loss\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleConvNet()\n",
    "if use_cuda:\n",
    "    model = model.float().cuda()\n",
    "criterion = F.binary_cross_entropy_with_logits\n",
    "optimizer = VOGN(model, train_set_size=6912, prec_init=1e2, num_samples=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0]:\n",
      "## Epoch[0], Train Loss: 0.543661   &   Train Accuracy: 0.576244\n",
      "Epoch[1]:\n",
      "## Epoch[1], Train Loss: 0.541200   &   Train Accuracy: 0.568721\n",
      "Epoch[2]:\n",
      "## Epoch[2], Train Loss: 0.617417   &   Train Accuracy: 0.547309\n",
      "Epoch[3]:\n",
      "## Epoch[3], Train Loss: 0.585955   &   Train Accuracy: 0.606192\n",
      "Epoch[4]:\n",
      "## Epoch[4], Train Loss: 0.813239   &   Train Accuracy: 0.516348\n",
      "Epoch[5]:\n",
      "## Epoch[5], Train Loss: 0.824004   &   Train Accuracy: 0.551071\n",
      "Epoch[6]:\n",
      "## Epoch[6], Train Loss: 0.775824   &   Train Accuracy: 0.593027\n",
      "Epoch[7]:\n",
      "## Epoch[7], Train Loss: 0.762786   &   Train Accuracy: 0.619068\n",
      "Epoch[8]:\n",
      "## Epoch[8], Train Loss: 0.731797   &   Train Accuracy: 0.624566\n",
      "Epoch[9]:\n",
      "## Epoch[9], Train Loss: 0.718731   &   Train Accuracy: 0.631655\n",
      "Epoch[10]:\n",
      "## Epoch[10], Train Loss: 0.657994   &   Train Accuracy: 0.660735\n",
      "Epoch[11]:\n",
      "## Epoch[11], Train Loss: 0.589763   &   Train Accuracy: 0.690538\n",
      "Epoch[12]:\n",
      "## Epoch[12], Train Loss: 0.609310   &   Train Accuracy: 0.692853\n",
      "Epoch[13]:\n",
      "## Epoch[13], Train Loss: 0.496569   &   Train Accuracy: 0.717593\n",
      "Epoch[14]:\n",
      "## Epoch[14], Train Loss: 0.461936   &   Train Accuracy: 0.721499\n"
     ]
    }
   ],
   "source": [
    "model, train_loss, train_accuracy = train_model_bb([11,10,9,8,7,6,5,4,3,2,1,0],model, [dataset_loader, dataset_loader], criterion,\n",
    "optimizer, num_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_bb(model, data_loader, optimizer,mc_samples):\n",
    "    a=0\n",
    "    for i in (data_loader):\n",
    "            inputs = i['data']\n",
    "            labels = i['label']\n",
    "            \n",
    "    if use_cuda:\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                \n",
    "    return optimizer.get_mc_predictions(model.forward,inputs,mc_samples=mc_samples)[0]>0,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.002560377120972\n"
     ]
    }
   ],
   "source": [
    "predict = torch.zeros(100,6912).cuda()\n",
    "labz = torch.zeros(100,6912).cuda()\n",
    "start = time.time()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(100):\n",
    "        predictions,lbl = inference_bb(model, inference_loader,optimizer,1)\n",
    "        predict[i] = predictions.view(6912)\n",
    "        labz[i] = lbl.view(6912)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15, 0.21, 0.93, ..., 0.95, 0.23, 0.91], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_train = np.sum(predict[:,:4146].cpu().numpy(),axis=0)/100\n",
    "predict_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.15, 0.21, 0.93, 0.9 , 0.9 , 0.29, 0.7 , 0.93, 0.17, 0.13, 0.09,\n",
       "        0.69], dtype=float32),\n",
       " array([0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_train[:12],Y[:12].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(predict_train, bins='auto')\n",
    "plt.title(\"Histogram with 'auto' bins\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f (x):\n",
    "    return x*(1-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =list(np.argsort(f(predict_train))[3746:])+[11,10,9,8,7,6,5,4,3,2,1,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(412,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sort(reverse = True)\n",
    "\n",
    "a = list(dict.fromkeys(a))\n",
    "predict_train[a].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxtrain = X[a]\n",
    "yytrain = Y[a]\n",
    "yytrain.shape\n",
    "file_train = csvDataset(xxtrain,yytrain,transform= ToTensor())\n",
    "final_train_loader = torch.utils.data.DataLoader(file_train,\n",
    "                                             batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = F.binary_cross_entropy_with_logits\n",
    "optimizer = VOGN(model, train_set_size=412, prec_init=1e2, num_samples=10)\n",
    "optimizer_bb = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0]:\n",
      "Iteration[101]:  Train Accuracy: 0.837379 \n",
      "## Epoch[0], Train Loss: 0.024900   &   Train Accuracy: 0.907767\n",
      "Epoch[1]:\n",
      "Iteration[101]:  Train Accuracy: 0.890777 \n",
      "## Epoch[1], Train Loss: 0.017478   &   Train Accuracy: 0.968447\n",
      "Epoch[2]:\n",
      "Iteration[101]:  Train Accuracy: 0.953883 \n",
      "## Epoch[2], Train Loss: 0.004618   &   Train Accuracy: 0.958738\n",
      "Epoch[3]:\n",
      "Iteration[101]:  Train Accuracy: 0.968447 \n",
      "## Epoch[3], Train Loss: 0.000051   &   Train Accuracy: 0.973301\n",
      "Epoch[4]:\n",
      "Iteration[101]:  Train Accuracy: 0.985437 \n",
      "## Epoch[4], Train Loss: 0.000024   &   Train Accuracy: 0.968447\n",
      "Epoch[5]:\n",
      "Iteration[101]:  Train Accuracy: 0.992718 \n",
      "## Epoch[5], Train Loss: 0.000017   &   Train Accuracy: 0.997573\n",
      "Epoch[6]:\n",
      "Iteration[101]:  Train Accuracy: 0.997573 \n",
      "## Epoch[6], Train Loss: 0.000010   &   Train Accuracy: 0.987864\n",
      "Epoch[7]:\n",
      "Iteration[101]:  Train Accuracy: 0.997573 \n",
      "## Epoch[7], Train Loss: 0.000008   &   Train Accuracy: 0.990291\n",
      "Epoch[8]:\n",
      "Iteration[101]:  Train Accuracy: 0.995146 \n",
      "## Epoch[8], Train Loss: 0.000006   &   Train Accuracy: 0.992718\n",
      "Epoch[9]:\n",
      "Iteration[101]:  Train Accuracy: 0.997573 \n",
      "## Epoch[9], Train Loss: 0.000001   &   Train Accuracy: 0.997573\n",
      "Epoch[10]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[10], Train Loss: 0.000002   &   Train Accuracy: 0.953883\n",
      "Epoch[11]:\n",
      "Iteration[101]:  Train Accuracy: 0.888350 \n",
      "## Epoch[11], Train Loss: 0.000000   &   Train Accuracy: 0.987864\n",
      "Epoch[12]:\n",
      "Iteration[101]:  Train Accuracy: 0.995146 \n",
      "## Epoch[12], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[13]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[13], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[14]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[14], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[15]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[15], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[16]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[16], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[17]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[17], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[18]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[18], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[19]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[19], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[20]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[20], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[21]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[21], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[22]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[22], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[23]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[23], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[24]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[24], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[25]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[25], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[26]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[26], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[27]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[27], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[28]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[28], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[29]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[29], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[30]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[30], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[31]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[31], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[32]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[32], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[33]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[33], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[34]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[34], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[35]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[35], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[36]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[36], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[37]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[37], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[38]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[38], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[39]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[39], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[40]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[40], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[41]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[41], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[42]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[42], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[43]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[43], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[44]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[44], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[45]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[45], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[46]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[46], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[47]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[47], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[48]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[48], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "Epoch[49]:\n",
      "Iteration[101]:  Train Accuracy: 1.000000 \n",
      "## Epoch[49], Train Loss: 0.000000   &   Train Accuracy: 1.000000\n",
      "56.2172966003418\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "model, train_loss, train_accuracy = train_model_cc(model, [final_train_loader, final_train_loader], criterion,\n",
    "optimizer_bb, num_epochs=50)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.166547060012817\n"
     ]
    }
   ],
   "source": [
    "predict = torch.zeros(100,6912).cuda()\n",
    "labz = torch.zeros(100,6912).cuda()\n",
    "start = time.time()\n",
    "for i in range(100):\n",
    "    predictions,lbl = inference_bb(model, inference_loader,optimizer,1)\n",
    "    predict[i] = predictions.view(6912)\n",
    "    labz[i] = lbl.view(6912)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6912,)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = (np.sum(predict.cpu().numpy(),axis=0)>0.5)*1.\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6912,), (2766,))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = (np.sum(labz.cpu().numpy(),axis=0)>0.5)*1.\n",
    "labels.shape,labels[4146:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3188720173535792\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(result[4146:]==labels[4146:])/2766)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.615 ///0.656"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4146,)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_train = np.sum(predict[:,:4146].cpu().numpy(),axis=0)/100\n",
    "predict_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(predict_train, bins='auto')\n",
    "plt.title(\"Histogram with 'auto' bins\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in inference_loader:\n",
    "        inputs = i['data']\n",
    "        labels = i['label']\n",
    "        if use_cuda:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        out = model.forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (out.cpu().numpy()>0)*1.\n",
    "labels = (labels.cpu().numpy())*1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.868763557483731\n"
     ]
    }
   ],
   "source": [
    "correct = print(np.sum(pred[4146:]==labels[4146:])/2766)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
