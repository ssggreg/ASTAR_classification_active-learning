{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from vogn import VOGN\n",
    "from models import SimpleConvNet\n",
    "from datasets import Dataset\n",
    "from utils import train_model\n",
    "from utils import inference\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "sns.set()\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : attention aux colums de file_A et file, columns en plus etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Cuda: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fec5f2b2b30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Test wether GPUs are available\n",
    "use_cuda =  torch.cuda.is_available()\n",
    "print(\"Using Cuda: %s\" % use_cuda)\n",
    "\n",
    "# Set Random Seed\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class csvDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        \n",
    "        file = pd.read_csv(csv_file)\n",
    "        \n",
    "        \n",
    "        a=['Pass/Fail']\n",
    "        \n",
    "        self.label = np.array(file[a].values=='Fail')*(-1.)+1\n",
    "        \n",
    "        a = []\n",
    "        \n",
    "        for i in list(file_A.columns):\n",
    "            if i != 'Pass/Fail':\n",
    "                a.append(i)\n",
    "                \n",
    "        data = np.array(file[a].values)       \n",
    "        for i in range(16):\n",
    "            data[:,i]=(data[:,i] - data[:,i].mean())/(data[:,i].std())\n",
    "                \n",
    "        self.data = data\n",
    "         \n",
    "        #self.train_set = TensorDataset()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        data = self.data[idx]\n",
    "        label = self.label[idx]\n",
    "        sample = { 'data': data,'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "    \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        \n",
    "        data, label  = sample['data'],sample['label']\n",
    "        \n",
    "        \n",
    "        return {'data': torch.from_numpy(data).float(),\n",
    "                'label': torch.from_numpy(label).float()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(type(self), self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(16, 64)\n",
    "        self.layer2 = nn.Linear(64, 256)\n",
    "        self.layer3 = nn.Linear(256, 256)\n",
    "        self.layer4 = nn.Linear(256, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.relu(self.layer3(x))\n",
    "        out = self.layer4(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dataset = csvDataset(csv_file='circuit-design/opAmp_280nm_GF55_Mod_30P.csv',transform= ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        , -1.22474487, -1.        , ...,  1.41675504,\n",
       "         0.        , 30.93171296],\n",
       "       [-1.        , -1.22474487, -1.        , ...,  1.04780248,\n",
       "         0.        ,         nan],\n",
       "       [-1.        , -1.22474487, -1.        , ...,  1.1953835 ,\n",
       "         0.        ,         nan],\n",
       "       ...,\n",
       "       [ 1.        ,  1.22474487,  1.        , ..., -0.77166073,\n",
       "         0.        ,         nan],\n",
       "       [ 1.        ,  1.22474487,  1.        , ..., -0.74952358,\n",
       "         0.        ,         nan],\n",
       "       [ 1.        ,  1.22474487,  1.        , ..., -0.78905421,\n",
       "         0.        ,         nan]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = pd.read_csv('circuit-design/opAmp_280nm_GF55_Mod_30P.csv')\n",
    "        \n",
    "        \n",
    "a=['Pass/Fail']\n",
    "        \n",
    "label = np.array(file[a].values=='Fail')*(-1.)+1\n",
    "        \n",
    "a = []\n",
    "        \n",
    "for i in list(file.columns):\n",
    "    if i != 'Pass/Fail':\n",
    "        a.append(i)\n",
    "                \n",
    "data = np.array(file[a].values)   \n",
    "\n",
    "for i in range(16):\n",
    "    data[:,i]=(data[:,i] - data[:,i].mean())/(data[:,i].std())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_A = pd.read_csv('circuit-design/opAmp_280nm_GF55.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VDD', 'Ib', 'Lg1', 'Lg2', 'Lrf', 'Wcf', 'Wg1', 'Wg2', 'temperature',\n",
       "       'Pass/Fail', 'ACM_G', 'SR', 'CMRR', 'NOISE', 'PSRR', 'PhaseMargin_PM',\n",
       "       'BandWidth', 'Pass/Fail.1', 'Percentage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VDD', 'Ib', 'Lg1', 'Lg2', 'Lrf', 'Wcf', 'Wg1', 'Wg2', 'temperature',\n",
       "       'Pass/Fail', 'ACM_G', 'SR', 'CMRR', 'NOISE', 'PSRR', 'PhaseMargin_PM',\n",
       "       'BandWidth'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_A.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_loader = torch.utils.data.DataLoader(file_dataset,batch_size=43, shuffle=True)\n",
    "dataset_loader = torch.utils.data.DataLoader(file_dataset,\n",
    "                                             batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_bb(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    \"\"\"\n",
    "    Performs Training and Validation on test set on the given model using the specified optimizer\n",
    "    :param model: (nn.Module) Model to be trained\n",
    "    :param dataloaders: (list) train and test dataloaders\n",
    "    :param criterion: Loss Function\n",
    "    :param optimizer: Optimizer to be used for training\n",
    "    :param num_epochs: Number of epochs to train the model\n",
    "    :return: trained model, test and train metric history\n",
    "    \"\"\"\n",
    "    train_loss_history = []\n",
    "    train_accuracy_history = []\n",
    "    test_accuracy_history = []\n",
    "    test_loss_history = []\n",
    "    trainloader, testloader = dataloaders\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train(True)\n",
    "        print('Epoch[%d]:' % epoch)\n",
    "        running_train_loss = 0.\n",
    "        a=0\n",
    "        for i in (trainloader):\n",
    "            a+=1\n",
    "            inputs = i['data']\n",
    "            labels = i['label']\n",
    "            if use_cuda:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            if isinstance(optimizer, VOGN):\n",
    "                def closure():\n",
    "                    optimizer.zero_grad()\n",
    "                    logits = model.forward(inputs)\n",
    "                    loss = criterion(logits, labels)\n",
    "                    return loss\n",
    "            else:\n",
    "                def closure():\n",
    "                    optimizer.zero_grad()\n",
    "                    logits = model.forward(inputs)\n",
    "                    loss = criterion(logits, labels)\n",
    "                    loss.backward()\n",
    "                    return loss\n",
    "            loss = optimizer.step(closure)\n",
    "            running_train_loss += loss.detach().item()\n",
    "\n",
    "            # Print Training Progress\n",
    "            if a%500 == 1:\n",
    "                train_accuracy = accuracy_bb(model, trainloader)\n",
    "                print('Iteration[%d]: Train Loss: %f   Train Accuracy: %f ' % (a+1, running_train_loss/a, train_accuracy))\n",
    "\n",
    "        train_accuracy, train_loss = accuracy_bb(model, trainloader, criterion)\n",
    "        train_accuracy_history.append(train_accuracy)\n",
    "        train_loss_history.append(train_loss)\n",
    "        print('## Epoch[%d], Train Loss: %f   &   Train Accuracy: %f' % (epoch, train_loss, train_accuracy))\n",
    "    return model, train_loss_history, train_accuracy_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_bb(model, dataloader, criterion=None):\n",
    "    \"\"\" Computes the model's classification accuracy on the train dataset\n",
    "        Computes classification accuracy and loss(optional) on the test dataset\n",
    "        The model should return logits\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0.\n",
    "        running_loss = 0.\n",
    "        for i in (dataloader):\n",
    "            inputs = i['data']\n",
    "            labels = i['label']\n",
    "            if use_cuda:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            if criterion is not None:\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item()\n",
    "            pred = (outputs>0).float()\n",
    "            correct += (pred.view(-1,1) == labels).sum().item()\n",
    "        accuracy = correct / len(dataloader.dataset)\n",
    "        if criterion is not None:\n",
    "            running_loss = running_loss / len(dataloader)\n",
    "            return accuracy, running_loss\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleConvNet()\n",
    "if use_cuda:\n",
    "    model = model.float().cuda()\n",
    "criterion = F.binary_cross_entropy_with_logits\n",
    "optimizer = VOGN(model, train_set_size=6912, prec_init=1e2, num_samples=4)\n",
    "optimizer_bb = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0]:\n",
      "Iteration[2]: Train Loss: 0.618195   Train Accuracy: 0.690683 \n",
      "Iteration[502]: Train Loss: 0.429260   Train Accuracy: 0.850984 \n",
      "Iteration[1002]: Train Loss: 0.361642   Train Accuracy: 0.862558 \n",
      "Iteration[1502]: Train Loss: 0.328902   Train Accuracy: 0.885272 \n",
      "Iteration[2002]: Train Loss: 0.313633   Train Accuracy: 0.900608 \n",
      "Iteration[2502]: Train Loss: 0.293588   Train Accuracy: 0.891927 \n",
      "Iteration[3002]: Train Loss: 0.281464   Train Accuracy: 0.931279 \n",
      "Iteration[3502]: Train Loss: 0.272258   Train Accuracy: 0.932726 \n",
      "Iteration[4002]: Train Loss: 0.259963   Train Accuracy: 0.927807 \n",
      "Iteration[4502]: Train Loss: 0.251183   Train Accuracy: 0.940394 \n",
      "Iteration[5002]: Train Loss: 0.240842   Train Accuracy: 0.939091 \n",
      "Iteration[5502]: Train Loss: 0.230948   Train Accuracy: 0.958623 \n",
      "Iteration[6002]: Train Loss: 0.223748   Train Accuracy: 0.944444 \n",
      "Iteration[6502]: Train Loss: 0.215162   Train Accuracy: 0.964265 \n",
      "## Epoch[0], Train Loss: 0.106087   &   Train Accuracy: 0.954282\n",
      "Epoch[1]:\n",
      "Iteration[2]: Train Loss: 0.218947   Train Accuracy: 0.953848 \n",
      "Iteration[502]: Train Loss: 0.111183   Train Accuracy: 0.954716 \n",
      "Iteration[1002]: Train Loss: 0.108181   Train Accuracy: 0.955584 \n",
      "Iteration[1502]: Train Loss: 0.111001   Train Accuracy: 0.949074 \n",
      "Iteration[2002]: Train Loss: 0.113315   Train Accuracy: 0.965133 \n",
      "Iteration[2502]: Train Loss: 0.118641   Train Accuracy: 0.960503 \n",
      "Iteration[3002]: Train Loss: 0.116676   Train Accuracy: 0.972222 \n",
      "Iteration[3502]: Train Loss: 0.113578   Train Accuracy: 0.953559 \n",
      "Iteration[4002]: Train Loss: 0.113688   Train Accuracy: 0.964554 \n",
      "Iteration[4502]: Train Loss: 0.112683   Train Accuracy: 0.976852 \n",
      "Iteration[5002]: Train Loss: 0.110937   Train Accuracy: 0.976273 \n",
      "Iteration[5502]: Train Loss: 0.107459   Train Accuracy: 0.979456 \n",
      "Iteration[6002]: Train Loss: 0.106260   Train Accuracy: 0.971499 \n",
      "Iteration[6502]: Train Loss: 0.104220   Train Accuracy: 0.975839 \n",
      "## Epoch[1], Train Loss: 0.062452   &   Train Accuracy: 0.971933\n",
      "Epoch[2]:\n",
      "Iteration[2]: Train Loss: 0.037794   Train Accuracy: 0.971644 \n",
      "Iteration[502]: Train Loss: 0.085752   Train Accuracy: 0.968171 \n",
      "Iteration[1002]: Train Loss: 0.079046   Train Accuracy: 0.969618 \n",
      "Iteration[1502]: Train Loss: 0.078195   Train Accuracy: 0.966146 \n",
      "Iteration[2002]: Train Loss: 0.080479   Train Accuracy: 0.976562 \n",
      "Iteration[2502]: Train Loss: 0.081271   Train Accuracy: 0.973958 \n",
      "Iteration[3002]: Train Loss: 0.085295   Train Accuracy: 0.970486 \n",
      "Iteration[3502]: Train Loss: 0.082866   Train Accuracy: 0.970631 \n",
      "Iteration[4002]: Train Loss: 0.079516   Train Accuracy: 0.968895 \n",
      "Iteration[4502]: Train Loss: 0.077792   Train Accuracy: 0.979456 \n",
      "Iteration[5002]: Train Loss: 0.078479   Train Accuracy: 0.985243 \n",
      "Iteration[5502]: Train Loss: 0.077848   Train Accuracy: 0.970775 \n",
      "Iteration[6002]: Train Loss: 0.079171   Train Accuracy: 0.982494 \n",
      "Iteration[6502]: Train Loss: 0.077580   Train Accuracy: 0.971209 \n",
      "## Epoch[2], Train Loss: 0.068135   &   Train Accuracy: 0.974537\n",
      "Epoch[3]:\n",
      "Iteration[2]: Train Loss: 0.000000   Train Accuracy: 0.974537 \n",
      "Iteration[502]: Train Loss: 0.086286   Train Accuracy: 0.982494 \n",
      "Iteration[1002]: Train Loss: 0.057650   Train Accuracy: 0.983218 \n",
      "Iteration[1502]: Train Loss: 0.072677   Train Accuracy: 0.978588 \n",
      "Iteration[2002]: Train Loss: 0.064500   Train Accuracy: 0.982350 \n",
      "Iteration[2502]: Train Loss: 0.064913   Train Accuracy: 0.980613 \n",
      "Iteration[3002]: Train Loss: 0.065360   Train Accuracy: 0.975405 \n",
      "Iteration[3502]: Train Loss: 0.065816   Train Accuracy: 0.978443 \n",
      "Iteration[4002]: Train Loss: 0.062140   Train Accuracy: 0.986111 \n",
      "Iteration[4502]: Train Loss: 0.061946   Train Accuracy: 0.981047 \n",
      "Iteration[5002]: Train Loss: 0.062836   Train Accuracy: 0.974682 \n",
      "Iteration[5502]: Train Loss: 0.066188   Train Accuracy: 0.980758 \n",
      "Iteration[6002]: Train Loss: 0.064554   Train Accuracy: 0.989149 \n",
      "Iteration[6502]: Train Loss: 0.063322   Train Accuracy: 0.983941 \n",
      "## Epoch[3], Train Loss: 0.029302   &   Train Accuracy: 0.988571\n",
      "Epoch[4]:\n",
      "Iteration[2]: Train Loss: 0.000000   Train Accuracy: 0.988281 \n",
      "Iteration[502]: Train Loss: 0.066844   Train Accuracy: 0.982060 \n",
      "Iteration[1002]: Train Loss: 0.066132   Train Accuracy: 0.984086 \n",
      "Iteration[1502]: Train Loss: 0.058975   Train Accuracy: 0.985677 \n",
      "Iteration[2002]: Train Loss: 0.054353   Train Accuracy: 0.987413 \n",
      "Iteration[2502]: Train Loss: 0.063853   Train Accuracy: 0.981192 \n",
      "Iteration[3002]: Train Loss: 0.058696   Train Accuracy: 0.985243 \n",
      "Iteration[3502]: Train Loss: 0.054958   Train Accuracy: 0.982639 \n",
      "Iteration[4002]: Train Loss: 0.057504   Train Accuracy: 0.979601 \n",
      "Iteration[4502]: Train Loss: 0.056996   Train Accuracy: 0.971933 \n",
      "Iteration[5002]: Train Loss: 0.057338   Train Accuracy: 0.977286 \n",
      "Iteration[5502]: Train Loss: 0.059209   Train Accuracy: 0.978299 \n",
      "Iteration[6002]: Train Loss: 0.059216   Train Accuracy: 0.981481 \n",
      "Iteration[6502]: Train Loss: 0.060306   Train Accuracy: 0.982350 \n",
      "## Epoch[4], Train Loss: 0.044236   &   Train Accuracy: 0.982784\n",
      "Epoch[5]:\n",
      "Iteration[2]: Train Loss: 0.000000   Train Accuracy: 0.982784 \n",
      "Iteration[502]: Train Loss: 0.059987   Train Accuracy: 0.988715 \n",
      "Iteration[1002]: Train Loss: 0.055151   Train Accuracy: 0.979456 \n",
      "Iteration[1502]: Train Loss: 0.051863   Train Accuracy: 0.979311 \n",
      "Iteration[2002]: Train Loss: 0.055211   Train Accuracy: 0.990596 \n",
      "Iteration[2502]: Train Loss: 0.052092   Train Accuracy: 0.989583 \n",
      "Iteration[3002]: Train Loss: 0.049853   Train Accuracy: 0.976562 \n",
      "Iteration[3502]: Train Loss: 0.051222   Train Accuracy: 0.975116 \n",
      "Iteration[4002]: Train Loss: 0.052789   Train Accuracy: 0.988426 \n",
      "Iteration[4502]: Train Loss: 0.054382   Train Accuracy: 0.977286 \n",
      "Iteration[5002]: Train Loss: 0.053466   Train Accuracy: 0.989149 \n",
      "Iteration[5502]: Train Loss: 0.052825   Train Accuracy: 0.984520 \n",
      "Iteration[6002]: Train Loss: 0.052889   Train Accuracy: 0.975260 \n",
      "Iteration[6502]: Train Loss: 0.052675   Train Accuracy: 0.989873 \n",
      "## Epoch[5], Train Loss: 0.040999   &   Train Accuracy: 0.983796\n",
      "Epoch[6]:\n",
      "Iteration[2]: Train Loss: 0.000000   Train Accuracy: 0.983796 \n",
      "Iteration[502]: Train Loss: 0.022467   Train Accuracy: 0.989439 \n",
      "Iteration[1002]: Train Loss: 0.027663   Train Accuracy: 0.989149 \n",
      "Iteration[1502]: Train Loss: 0.043478   Train Accuracy: 0.981047 \n",
      "Iteration[2002]: Train Loss: 0.049405   Train Accuracy: 0.983362 \n",
      "Iteration[2502]: Train Loss: 0.046659   Train Accuracy: 0.973814 \n",
      "Iteration[3002]: Train Loss: 0.048237   Train Accuracy: 0.981192 \n",
      "Iteration[3502]: Train Loss: 0.047314   Train Accuracy: 0.980613 \n",
      "Iteration[4002]: Train Loss: 0.044794   Train Accuracy: 0.989583 \n",
      "Iteration[4502]: Train Loss: 0.043547   Train Accuracy: 0.968316 \n",
      "Iteration[5002]: Train Loss: 0.044017   Train Accuracy: 0.977431 \n",
      "Iteration[5502]: Train Loss: 0.043951   Train Accuracy: 0.979745 \n",
      "Iteration[6002]: Train Loss: 0.045926   Train Accuracy: 0.989728 \n",
      "Iteration[6502]: Train Loss: 0.045955   Train Accuracy: 0.985243 \n",
      "## Epoch[6], Train Loss: 0.142577   &   Train Accuracy: 0.973090\n",
      "Epoch[7]:\n",
      "Iteration[2]: Train Loss: 0.000000   Train Accuracy: 0.973090 \n",
      "Iteration[502]: Train Loss: 0.058982   Train Accuracy: 0.973814 \n",
      "Iteration[1002]: Train Loss: 0.051399   Train Accuracy: 0.987703 \n",
      "Iteration[1502]: Train Loss: 0.045490   Train Accuracy: 0.969473 \n",
      "Iteration[2002]: Train Loss: 0.048474   Train Accuracy: 0.983218 \n",
      "Iteration[2502]: Train Loss: 0.046908   Train Accuracy: 0.989149 \n",
      "Iteration[3002]: Train Loss: 0.050201   Train Accuracy: 0.988860 \n",
      "Iteration[3502]: Train Loss: 0.050531   Train Accuracy: 0.980035 \n",
      "Iteration[4002]: Train Loss: 0.049280   Train Accuracy: 0.988281 \n",
      "Iteration[4502]: Train Loss: 0.049592   Train Accuracy: 0.982639 \n",
      "Iteration[5002]: Train Loss: 0.049057   Train Accuracy: 0.985966 \n",
      "Iteration[5502]: Train Loss: 0.048247   Train Accuracy: 0.991753 \n",
      "Iteration[6002]: Train Loss: 0.049394   Train Accuracy: 0.979456 \n",
      "Iteration[6502]: Train Loss: 0.048547   Train Accuracy: 0.990596 \n",
      "## Epoch[7], Train Loss: 0.037203   &   Train Accuracy: 0.988426\n",
      "Epoch[8]:\n",
      "Iteration[2]: Train Loss: 0.005213   Train Accuracy: 0.988426 \n",
      "Iteration[502]: Train Loss: 0.058908   Train Accuracy: 0.984375 \n",
      "Iteration[1002]: Train Loss: 0.047094   Train Accuracy: 0.992766 \n",
      "Iteration[1502]: Train Loss: 0.045419   Train Accuracy: 0.990885 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration[2002]: Train Loss: 0.041667   Train Accuracy: 0.983218 \n",
      "Iteration[2502]: Train Loss: 0.040505   Train Accuracy: 0.986979 \n",
      "Iteration[3002]: Train Loss: 0.047357   Train Accuracy: 0.989583 \n",
      "Iteration[3502]: Train Loss: 0.045935   Train Accuracy: 0.993634 \n",
      "Iteration[4002]: Train Loss: 0.044138   Train Accuracy: 0.993345 \n",
      "Iteration[4502]: Train Loss: 0.040948   Train Accuracy: 0.990162 \n",
      "Iteration[5002]: Train Loss: 0.042103   Train Accuracy: 0.987558 \n",
      "Iteration[5502]: Train Loss: 0.042507   Train Accuracy: 0.989728 \n",
      "Iteration[6002]: Train Loss: 0.042036   Train Accuracy: 0.989149 \n",
      "Iteration[6502]: Train Loss: 0.043347   Train Accuracy: 0.983073 \n",
      "## Epoch[8], Train Loss: 0.050785   &   Train Accuracy: 0.984086\n",
      "Epoch[9]:\n",
      "Iteration[2]: Train Loss: 0.000000   Train Accuracy: 0.984086 \n",
      "Iteration[502]: Train Loss: 0.046297   Train Accuracy: 0.987269 \n",
      "Iteration[1002]: Train Loss: 0.040304   Train Accuracy: 0.981047 \n",
      "Iteration[1502]: Train Loss: 0.039975   Train Accuracy: 0.989439 \n",
      "Iteration[2002]: Train Loss: 0.039945   Train Accuracy: 0.990162 \n",
      "Iteration[2502]: Train Loss: 0.036840   Train Accuracy: 0.987847 \n",
      "Iteration[3002]: Train Loss: 0.037496   Train Accuracy: 0.980179 \n",
      "Iteration[3502]: Train Loss: 0.041625   Train Accuracy: 0.978733 \n",
      "Iteration[4002]: Train Loss: 0.040643   Train Accuracy: 0.977286 \n",
      "Iteration[4502]: Train Loss: 0.039642   Train Accuracy: 0.985532 \n",
      "Iteration[5002]: Train Loss: 0.039314   Train Accuracy: 0.986545 \n",
      "Iteration[5502]: Train Loss: 0.038489   Train Accuracy: 0.989728 \n",
      "Iteration[6002]: Train Loss: 0.036861   Train Accuracy: 0.988860 \n",
      "Iteration[6502]: Train Loss: 0.036585   Train Accuracy: 0.987847 \n",
      "## Epoch[9], Train Loss: 0.028409   &   Train Accuracy: 0.991175\n"
     ]
    }
   ],
   "source": [
    "model, train_loss, train_accuracy = train_model_bb(model, [dataset_loader, dataset_loader], criterion,\n",
    "optimizer_bb, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleConvNet()\n",
    "if use_cuda:\n",
    "    model = model.float().cuda()\n",
    "criterion = F.binary_cross_entropy_with_logits\n",
    "optimizer = VOGN(model, train_set_size=6912, prec_init=1e2, num_samples=10)\n",
    "optimizer_bb = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0]:\n",
      "Iteration[2]: Train Loss: 0.848696   Train Accuracy: 0.309317 \n",
      "Iteration[502]: Train Loss: 0.593379   Train Accuracy: 0.740162 \n",
      "Iteration[1002]: Train Loss: 0.549415   Train Accuracy: 0.751881 \n",
      "Iteration[1502]: Train Loss: 0.539353   Train Accuracy: 0.828125 \n",
      "Iteration[2002]: Train Loss: 0.545150   Train Accuracy: 0.808594 \n",
      "Iteration[2502]: Train Loss: 1.227444   Train Accuracy: 0.681134 \n",
      "Iteration[3002]: Train Loss: 1.221182   Train Accuracy: 0.690104 \n",
      "Iteration[3502]: Train Loss: 1.291220   Train Accuracy: 0.690683 \n",
      "Iteration[4002]: Train Loss: 1.249052   Train Accuracy: 0.690683 \n",
      "Iteration[4502]: Train Loss: 1.217457   Train Accuracy: 0.690683 \n",
      "Iteration[5002]: Train Loss: 1.264316   Train Accuracy: 0.688657 \n",
      "Iteration[5502]: Train Loss: 1.247096   Train Accuracy: 0.690683 \n",
      "Iteration[6002]: Train Loss: 1.265742   Train Accuracy: 0.690683 \n",
      "Iteration[6502]: Train Loss: 1.304199   Train Accuracy: 0.690683 \n",
      "## Epoch[0], Train Loss: 0.489695   &   Train Accuracy: 0.690683\n",
      "Epoch[1]:\n",
      "Iteration[2]: Train Loss: 0.643369   Train Accuracy: 0.690683 \n",
      "Iteration[502]: Train Loss: 0.701747   Train Accuracy: 0.690683 \n",
      "Iteration[1002]: Train Loss: 1.008066   Train Accuracy: 0.682870 \n",
      "Iteration[1502]: Train Loss: 1.456944   Train Accuracy: 0.736256 \n",
      "Iteration[2002]: Train Loss: 2.996025   Train Accuracy: 0.690104 \n",
      "Iteration[2502]: Train Loss: 2.556183   Train Accuracy: 0.700087 \n",
      "Iteration[3002]: Train Loss: 2.290448   Train Accuracy: 0.783854 \n",
      "Iteration[3502]: Train Loss: 2.123792   Train Accuracy: 0.781684 \n",
      "Iteration[4002]: Train Loss: 1.985206   Train Accuracy: 0.783275 \n",
      "Iteration[4502]: Train Loss: 1.851421   Train Accuracy: 0.814381 \n",
      "Iteration[5002]: Train Loss: 1.729528   Train Accuracy: 0.852141 \n",
      "Iteration[5502]: Train Loss: 1.607201   Train Accuracy: 0.859086 \n",
      "Iteration[6002]: Train Loss: 1.628985   Train Accuracy: 0.822193 \n",
      "Iteration[6502]: Train Loss: 1.536832   Train Accuracy: 0.860822 \n",
      "## Epoch[1], Train Loss: 0.363242   &   Train Accuracy: 0.814959\n",
      "Epoch[2]:\n",
      "Iteration[2]: Train Loss: 0.126163   Train Accuracy: 0.816696 \n",
      "Iteration[502]: Train Loss: 0.455162   Train Accuracy: 0.727431 \n",
      "Iteration[1002]: Train Loss: 0.471267   Train Accuracy: 0.831019 \n",
      "Iteration[1502]: Train Loss: 0.581053   Train Accuracy: 0.868345 \n",
      "Iteration[2002]: Train Loss: 0.526351   Train Accuracy: 0.864005 \n",
      "Iteration[2502]: Train Loss: 0.589138   Train Accuracy: 0.890914 \n",
      "Iteration[3002]: Train Loss: 0.556321   Train Accuracy: 0.899306 \n",
      "Iteration[3502]: Train Loss: 0.549739   Train Accuracy: 0.906973 \n",
      "Iteration[4002]: Train Loss: 0.850834   Train Accuracy: 0.893374 \n",
      "Iteration[4502]: Train Loss: 0.788905   Train Accuracy: 0.902344 \n",
      "Iteration[5002]: Train Loss: 1.168635   Train Accuracy: 0.887008 \n",
      "Iteration[5502]: Train Loss: 1.090991   Train Accuracy: 0.895544 \n",
      "Iteration[6002]: Train Loss: 1.027843   Train Accuracy: 0.913628 \n",
      "Iteration[6502]: Train Loss: 0.977346   Train Accuracy: 0.904514 \n",
      "## Epoch[2], Train Loss: 0.209490   &   Train Accuracy: 0.911892\n",
      "351.18757796287537\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "model, train_loss, train_accuracy = train_model_bb(model, [dataset_loader, dataset_loader], criterion,\n",
    "optimizer, num_epochs=3)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention ne pas reentrainer !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_loader = torch.utils.data.DataLoader(file_dataset,\n",
    "                                             batch_size=6192, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_bb(model, data, optimizer,mc_samples):\n",
    "    a=0\n",
    "    for i in (inference_loader):\n",
    "        a+=1\n",
    "        if a == 1:\n",
    "            inputs = i['data']\n",
    "            labels = i['label']\n",
    "            \n",
    "    if use_cuda:\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                \n",
    "    return optimizer.get_mc_predictions(model.forward,inputs,mc_samples=mc_samples)[0]>0,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=inference_bb(model, inference_loader,optimizer,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = torch.zeros(1000,6192).cuda()\n",
    "labz = torch.zeros(1000,6192).cuda()\n",
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    predictions,lbl = inference_bb(model, inference_loader,optimizer,1)\n",
    "    predict[i] = predictions.view(6192)\n",
    "    labz[i] = lbl.view(6192)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist=torch.zeros(6192)\n",
    "histl=torch.zeros(6192)\n",
    "for i in range(6192):\n",
    "    hist[i] = torch.mean(predict[:,i])\n",
    "    histl[i] = torch.mean(labz[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(histl.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0\n",
    "for i in (inference_loader):\n",
    "        a+=1\n",
    "        inputs = i['data']\n",
    "        labels = i['label']\n",
    "        print(a,inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_loader.dataset.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crit(vect,thresh):\n",
    "    a = vect>thresh\n",
    "    b = vect < (1-thresh)\n",
    "\n",
    "    return a*b*1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(crit(hist.numpy(),0.20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def better_pred(labz,thresh,vect):\n",
    "\n",
    "    critz = crit(vect,thresh)\n",
    "    preds = vect>0.5\n",
    "    \n",
    "    correct_better = 0.\n",
    "    correct = 0.\n",
    "    correct+= np.sum((labz-preds)==0)\n",
    "    correct_better = np.sum(((labz-preds)==0)*(critz==0))\n",
    "    \n",
    "    return correct/6192,correct_better/(6192-np.sum(critz))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_pred(histl.numpy(),0.1,hist.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,0.5,601)\n",
    "rez = [better_pred(histl.numpy(),y,hist.numpy()) for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,rez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
