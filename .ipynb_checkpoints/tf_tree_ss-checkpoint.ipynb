{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active Learning for IC design by Ashish James, July 20, 2018\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import time\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from modAL.uncertainty import uncertainty_sampling\n",
    "from modAL.models import ActiveLearner, Committee\n",
    "\n",
    "##from models.model_clf import IC_Design_DNN_Clf\n",
    "\n",
    "scaler = StandardScaler()\n",
    "num_classes = 2\n",
    "REG_FLAG = False\n",
    "csv_file = \"circuit-design/opAmp_280nm_GF55_Mod_30P.csv\"  # Dataset1\n",
    "input_dims = 9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class IC_Design_DNN_Clf:\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def __call__(self, X, reuse=False):\n",
    "\n",
    "        with tf.variable_scope(self.name) as scope:\n",
    "\n",
    "            if reuse:\n",
    "                scope.reuse_variables()\n",
    "\n",
    "            dense1 = tf.layers.dense(inputs=X, units=64, activation=tf.nn.relu)\n",
    "            dense2 = tf.layers.dense(inputs=dense1, units=64, activation=tf.nn.relu)\n",
    "            # dense3 = tf.layers.dense(inputs=dense2, units=64, activation=tf.nn.relu)\n",
    "            outputs = tf.layers.dense(inputs=dense2, units=2, activation=tf.nn.relu)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    @property\n",
    "    def vars(self):\n",
    "        return tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=self.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gregoire/anaconda3/envs/pytorch_fury/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/gregoire/anaconda3/envs/pytorch_fury/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def read_data(csv_file):\n",
    "    data = pd.read_csv(csv_file)\n",
    "    input = data.iloc[:,0:9]    \n",
    "    if REG_FLAG:\n",
    "        output = data.iloc[:,10:17]        \n",
    "    else:\n",
    "        output = data.iloc[:,9]\n",
    "        integer_encoded = LabelEncoder().fit_transform(output)\n",
    "        output = to_categorical(integer_encoded)\n",
    "    return input, output\n",
    "input, output = read_data(csv_file)\n",
    "\n",
    "#logdir = 'tf_logs/Inverse_Prob'\n",
    "#ckptdir = logdir + '/model'\n",
    "#if not os.path.exists(logdir):\n",
    "#    os.mkdir(logdir)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.random.set_random_seed(1)\n",
    "\n",
    "with tf.name_scope('Classifier'):\n",
    "    # Initialize neural network\n",
    "    DNN = IC_Design_DNN_Clf('DNN')\n",
    "    # Setup training process\n",
    "    lmda = tf.placeholder_with_default(0.01, shape=[], name='lambda')\n",
    "    X = tf.placeholder(tf.float32, [None, 9], name='X')\n",
    "    Y = tf.placeholder(tf.float32, [None, 2], name='Y')\n",
    "\n",
    "    tf.add_to_collection('placeholders', lmda)\n",
    "\n",
    "    Targets = DNN(X)\n",
    "    Targets_s = tf.nn.sigmoid(Targets)\n",
    "\n",
    "    # cost = tf.reduce_mean(tf.square(Targets-Y))\n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Targets, labels=Y))\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost, var_list=DNN.vars)\n",
    "\n",
    "    # correct_prediction = Targets - Y\n",
    "    correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Targets_s, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    err_rate = 1 - accuracy\n",
    "\n",
    "cost_summary = tf.summary.scalar('Cost', cost)\n",
    "accuray_summary = tf.summary.scalar('Accuracy', accuracy)\n",
    "summary = tf.summary.merge_all()\n",
    "input_norm = scaler.fit_transform(input)\n",
    "scl_mean_ip = scaler.mean_\n",
    "scl_var_ip = scaler.var_\n",
    "# trainY = output #scaler.fit_transform(output)\n",
    "# scl_mean_op = scaler.mean_\n",
    "# scl_var_op = scaler.var_\n",
    "# Train, test and validation datasets\n",
    "trainX_tmp, testX, trainY_tmp, testY  = train_test_split(input_norm, output, test_size=0.2, random_state=1)\n",
    "trainX_tmp, valX, trainY_tmp, valY = train_test_split(trainX_tmp, trainY_tmp, test_size=0.25, random_state=1)\n",
    "\n",
    "sel_rate = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gregoire/anaconda3/envs/pytorch_fury/lib/python3.6/site-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n",
      "/home/gregoire/anaconda3/envs/pytorch_fury/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/gregoire/anaconda3/envs/pytorch_fury/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active\n",
      "45.35818433761597\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "start = time.time()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#saver = tf.train.Saver()\n",
    "#file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "\n",
    "#sel_met = 'random'\n",
    "sel_met = 'active'\n",
    "\n",
    "print (sel_met)\n",
    "       # -----------------------------------\n",
    "if sel_met == 'random':\n",
    "    # --------------------------------------------------------------\n",
    "    # No.1 Randomly select the train samples\n",
    "    trainY_tmp_lab = np.argmax(trainY_tmp, axis=1)\n",
    "    fail_ind = np.argwhere(trainY_tmp_lab == 0)[:,0]\n",
    "    pass_ind = np.argwhere(trainY_tmp_lab == 1)[:,0]\n",
    "\n",
    "    trainX_fail_tmp = trainX_tmp[fail_ind]\n",
    "    trainY_fail_tmp = trainY_tmp[fail_ind]\n",
    "    trainX_pass_tmp = trainX_tmp[pass_ind]\n",
    "    trainY_pass_tmp = trainY_tmp[pass_ind]\n",
    "\n",
    "    fail_ran = np.random.permutation(fail_ind.shape[0])\n",
    "    fail_sel = fail_ran[np.arange(0, np.int(np.dot(fail_ind.shape[0], sel_rate)), 1)]\n",
    "    pass_ran = np.random.permutation(pass_ind.shape[0])\n",
    "    pass_sel = pass_ran[np.arange(0, np.int(np.dot(pass_ind.shape[0], sel_rate)), 1)]\n",
    "\n",
    "    trainX_pass = trainX_pass_tmp[pass_sel]\n",
    "    trainY_pass = trainY_pass_tmp[pass_sel]\n",
    "    trainX_fail = trainX_fail_tmp[fail_sel]\n",
    "    trainY_fail = trainY_fail_tmp[fail_sel]\n",
    "\n",
    "    trainX = np.vstack((trainX_pass, trainX_fail))\n",
    "    trainY = np.vstack((trainY_pass, trainY_fail))\n",
    "\n",
    "else :\n",
    "    #---------------------------------------------------\n",
    "    #active learning  \n",
    "    #import pdb; pdb.set_trace()\n",
    "    n_members = 2\n",
    "    learner_list = list()\n",
    "\n",
    "    for member_idx in range(n_members):\n",
    "        # initial training data\n",
    "        n_initial = 2\n",
    "        initial_idx = np.random.choice(range(trainX_tmp.shape[0]), size=n_initial, replace=False)\n",
    "        trainX_initial = trainX_tmp[initial_idx]\n",
    "        trainY_initial = trainY_tmp[initial_idx][:,0]\n",
    "\n",
    "        trainX_pool = np.delete(trainX_tmp, initial_idx, axis = 0)\n",
    "        trainY_pool = np.delete(trainY_tmp[:,0], initial_idx)\n",
    "        trainY_pool_org = np.delete(trainY_tmp, initial_idx, axis = 0)\n",
    "\n",
    "        # initializing the active learner\n",
    "        learner = ActiveLearner(\n",
    "            estimator = RandomForestClassifier(),\n",
    "            # query_strategy = uncertainty_sampling,   \n",
    "            X_training = trainX_initial, y_training = trainY_initial\n",
    "            )\n",
    "        \n",
    "        learner_list.append(learner)\n",
    "\n",
    "    committee = Committee(learner_list = learner_list)\n",
    "\n",
    "    # unqueried_score = committee.score(trainX_tmp,trainY_tmp[:,0])\n",
    "    # performance_history = [unqueried_score]\n",
    "    # active learning\n",
    "    n_queries = np.int(np.dot(trainX_tmp.shape[0], sel_rate)) - n_initial\n",
    "\n",
    "    trainX = np.zeros(shape = (n_queries, 9))\n",
    "    trainY = np.zeros(shape = (n_queries, 2))\n",
    "    for idx in range(n_queries):\n",
    "        query_idx, query_instance = committee.query(trainX_pool)  \n",
    "        #print(query_idx)\n",
    "\n",
    "        committee.teach(trainX_pool[query_idx].reshape(1,-1), trainY_pool[query_idx]) \n",
    "        # performance_history.append(committee.score(trainX_tmp, trainY_tmp[:,0]))\n",
    "        trainX[idx] = trainX_pool[query_idx]\n",
    "        trainY[idx] = trainY_pool_org[query_idx]\n",
    "        trainX_pool, trainY_pool, trainY_pool_org = np.delete(trainX_pool, query_idx, axis = 0), np.delete(trainY_pool, query_idx, axis = 0), np.delete(trainY_pool_org, query_idx, axis = 0)\n",
    "# --------------------------------------------------------------------------------\n",
    "end = time.time()\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Tsize = 412 cost = 0.685513263 acc = 0.639902687 err_r = 0.316702843\n",
      "Epoch: 0002 Tsize = 412 cost = 0.638602732 acc = 0.644768867 err_r = 0.313810527\n",
      "Epoch: 0003 Tsize = 412 cost = 0.604618032 acc = 0.717761566 err_r = 0.181489527\n",
      "Epoch: 0004 Tsize = 412 cost = 0.571293286 acc = 0.795620447 err_r = 0.143167019\n",
      "Epoch: 0005 Tsize = 412 cost = 0.544226209 acc = 0.839416066 err_r = 0.135936379\n",
      "Epoch: 0006 Tsize = 412 cost = 0.520923407 acc = 0.875912414 err_r = 0.129428804\n",
      "Epoch: 0007 Tsize = 412 cost = 0.499700105 acc = 0.890510954 err_r = 0.119305849\n",
      "Epoch: 0008 Tsize = 412 cost = 0.484609636 acc = 0.907542584 err_r = 0.118582785\n",
      "Epoch: 0009 Tsize = 412 cost = 0.468743213 acc = 0.922141123 err_r = 0.113521338\n",
      "Epoch: 0010 Tsize = 412 cost = 0.459504563 acc = 0.929440393 err_r = 0.113521338\n",
      "Epoch: 0011 Tsize = 412 cost = 0.449278566 acc = 0.936739663 err_r = 0.108459890\n",
      "Epoch: 0012 Tsize = 412 cost = 0.439897373 acc = 0.946472022 err_r = 0.104844570\n",
      "Epoch: 0013 Tsize = 412 cost = 0.432622971 acc = 0.956204382 err_r = 0.093998551\n",
      "Epoch: 0014 Tsize = 412 cost = 0.424238001 acc = 0.958637472 err_r = 0.096167743\n",
      "Epoch: 0015 Tsize = 412 cost = 0.417962030 acc = 0.961070562 err_r = 0.096167743\n",
      "Epoch: 0016 Tsize = 412 cost = 0.410116884 acc = 0.961070562 err_r = 0.089660168\n",
      "Epoch: 0017 Tsize = 412 cost = 0.405704196 acc = 0.965936741 err_r = 0.088937104\n",
      "Epoch: 0018 Tsize = 412 cost = 0.399132965 acc = 0.965936741 err_r = 0.088214040\n",
      "Epoch: 0019 Tsize = 412 cost = 0.396200662 acc = 0.978102191 err_r = 0.088937104\n",
      "Epoch: 0020 Tsize = 412 cost = 0.389425371 acc = 0.980535281 err_r = 0.087490976\n",
      "Epoch: 0021 Tsize = 412 cost = 0.381982484 acc = 0.987834551 err_r = 0.085321784\n",
      "Epoch: 0022 Tsize = 412 cost = 0.378503589 acc = 0.990267640 err_r = 0.085321784\n",
      "Epoch: 0023 Tsize = 412 cost = 0.375269410 acc = 0.995133820 err_r = 0.092552423\n",
      "Epoch: 0024 Tsize = 412 cost = 0.369435465 acc = 0.995133820 err_r = 0.088937104\n",
      "Epoch: 0025 Tsize = 412 cost = 0.371149865 acc = 0.995133820 err_r = 0.084598720\n",
      "Epoch: 0026 Tsize = 412 cost = 0.370110199 acc = 0.997566910 err_r = 0.085321784\n",
      "Epoch: 0027 Tsize = 412 cost = 0.366600918 acc = 0.997566910 err_r = 0.098336935\n",
      "Epoch: 0028 Tsize = 412 cost = 0.365629733 acc = 0.995133820 err_r = 0.080983341\n",
      "Epoch: 0029 Tsize = 412 cost = 0.363497413 acc = 0.997566910 err_r = 0.083875656\n",
      "Epoch: 0030 Tsize = 412 cost = 0.361994866 acc = 0.997566910 err_r = 0.086044848\n",
      "Epoch: 0031 Tsize = 412 cost = 0.361733594 acc = 0.997566910 err_r = 0.079537213\n",
      "Epoch: 0032 Tsize = 412 cost = 0.360463405 acc = 1.000000000 err_r = 0.085321784\n",
      "Epoch: 0033 Tsize = 412 cost = 0.357309750 acc = 1.000000000 err_r = 0.077368021\n",
      "Epoch: 0034 Tsize = 412 cost = 0.356549908 acc = 1.000000000 err_r = 0.078091085\n",
      "Epoch: 0035 Tsize = 412 cost = 0.354387113 acc = 1.000000000 err_r = 0.086044848\n",
      "Epoch: 0036 Tsize = 412 cost = 0.355902791 acc = 1.000000000 err_r = 0.084598720\n",
      "Epoch: 0037 Tsize = 412 cost = 0.359566355 acc = 0.995133820 err_r = 0.083152592\n",
      "Epoch: 0038 Tsize = 412 cost = 0.353635148 acc = 1.000000000 err_r = 0.080260277\n",
      "Epoch: 0039 Tsize = 412 cost = 0.351327698 acc = 1.000000000 err_r = 0.086767912\n",
      "Epoch: 0040 Tsize = 412 cost = 0.354796225 acc = 0.997566910 err_r = 0.086044848\n",
      "Epoch: 0041 Tsize = 412 cost = 0.357641890 acc = 0.997566910 err_r = 0.068691254\n",
      "Epoch: 0042 Tsize = 412 cost = 0.352913355 acc = 1.000000000 err_r = 0.077368021\n",
      "Epoch: 0043 Tsize = 412 cost = 0.355031254 acc = 0.997566910 err_r = 0.086044848\n",
      "Epoch: 0044 Tsize = 412 cost = 0.356452777 acc = 0.997566910 err_r = 0.086044848\n",
      "Epoch: 0045 Tsize = 412 cost = 0.351978702 acc = 1.000000000 err_r = 0.079537213\n",
      "Epoch: 0046 Tsize = 412 cost = 0.353376410 acc = 1.000000000 err_r = 0.075921893\n",
      "Epoch: 0047 Tsize = 412 cost = 0.352847547 acc = 0.997566910 err_r = 0.076644957\n",
      "Epoch: 0048 Tsize = 412 cost = 0.352728624 acc = 0.995133820 err_r = 0.076644957\n",
      "Epoch: 0049 Tsize = 412 cost = 0.354623946 acc = 0.997566910 err_r = 0.084598720\n",
      "Epoch: 0050 Tsize = 412 cost = 0.351003734 acc = 1.000000000 err_r = 0.084598720\n",
      "Accuracy_Test = 0.912509024\n",
      "24.28872299194336\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "training_epochs = 50\n",
    "batch_size = 3\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    total_batch = int(trainX.shape[0] / batch_size)\n",
    "    \n",
    "    avg_cost = 0\n",
    "    avg_acc = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        ran_from = i * batch_size\n",
    "        ran_to = (i + 1) * batch_size\n",
    "        batch_xs = trainX[ran_from:ran_to]\n",
    "        batch_ys = trainY[ran_from:ran_to]\n",
    "        batch_ys = np.reshape(batch_ys, [batch_size, 2])\n",
    "        # batch_ys = batch_ys.values.reshape(batch_size, 1)\n",
    "        _, cc, aa, summary_str, tt, yy = sess.run([optimizer, cost, accuracy, summary, Targets, Y], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        \n",
    "        avg_cost += cc / total_batch\n",
    "        avg_acc += aa / total_batch\n",
    "\n",
    "        #file_writer.add_summary(summary_str, epoch * total_batch + i)\n",
    "\n",
    "    err_rate_val = sess.run(err_rate, feed_dict={X: valX, Y: valY})\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'Tsize =', '%d' % trainX.shape[0], 'cost =', '{:.9f}'.format(avg_cost), 'acc =', '{:.9f}'.format(avg_acc), 'err_r =', '{:.9f}'.format(err_rate_val),)\n",
    "\n",
    "acc_test = sess.run(accuracy, feed_dict={X: testX, Y: testY})\n",
    "print('Accuracy_Test =', '{:.9f}'.format(acc_test))\n",
    "    # saver.save(sess, ckptdir)\n",
    "\n",
    "sess.close()\n",
    "\n",
    "end = time.time()\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
