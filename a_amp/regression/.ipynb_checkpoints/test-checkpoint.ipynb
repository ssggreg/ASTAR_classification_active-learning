{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from Class_vogn import train_model_cc_fast,csvDataset,ToTensor\n",
    "import torch.nn.functional as F\n",
    "from active_function import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from vogn import VOGN\n",
    "\n",
    "class EvalNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_size=9, hidden=64, dropout_rate=None):\n",
    "        super(EvalNet, self).__init__()\n",
    "        self.dropout = dropout_rate\n",
    "        if dropout_rate:\n",
    "            self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.f1 = nn.Linear(in_size, hidden)\n",
    "        self.f2 = nn.Linear(hidden,  hidden)\n",
    "        self.f3 = nn.Linear(hidden,  7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = F.relu(self.f1(out))\n",
    "        if self.dropout:\n",
    "            out = self.dropout(out)\n",
    "        out = F.relu(self.f2(out))\n",
    "        if self.dropout:\n",
    "            out = self.dropout(out)\n",
    "        out = self.f3(out)\n",
    "        return out  \n",
    "    \n",
    "class BaseNet(nn.Module):\n",
    "    def __init__(self,dropout_rate=None):\n",
    "        super(type(self), self).__init__()\n",
    "        self.dropout = dropout_rate\n",
    "        if dropout_rate:\n",
    "            self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.layer1 = nn.Linear(9, 32)\n",
    "        self.layer2 = nn.Linear(32, 32)\n",
    "        self.layer3 = nn.Linear(32, 7)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        if self.dropout:\n",
    "            out = self.dropout(out)\n",
    "        x = F.relu(self.layer2(x))\n",
    "        if self.dropout:\n",
    "            out = self.dropout(out)\n",
    "        out = self.layer3(x)\n",
    "        return out\n",
    "\n",
    "def random(x):\n",
    "    a,b,c = x.shape\n",
    "    return np.mean(np.std(x,axis=0),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.ExcelFile('Test Case 1 - OpAmp_280nm_GF55.xlsx').parse()\n",
    "\n",
    "train = ['VDD','Ib','Lg1','Lg2','Lrf','Wcf','Wg1','Wg2','temperature']\n",
    "target = ['ACM_G','SR','CMRR','NOISE','PSRR','PhaseMargin_PM','BandWidth']\n",
    "\n",
    "X = df[train].values\n",
    "Y = df[target].values\n",
    "\n",
    "for i in range(9):\n",
    "    X[:,i]=(X[:,i] - X[:,i].mean())/(X[:,i].std())\n",
    "for i in range(7):\n",
    "    Y[:,i]=(Y[:,i] - Y[:,i].mean())/(Y[:,i].std())\n",
    "    \n",
    "trainX_tmp, Xtest, trainY_tmp, Ytest  = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "Xtrain, valX, Ytrain, valY = train_test_split(trainX_tmp, trainY_tmp, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6912, 9), (1383, 9), (1383, 9))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,Xtest.shape,valX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4146, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11663302, 0.11543351, 0.11426876, 0.11295651, 0.1112393 ,\n",
       "       0.11011583, 0.10738743, 0.10683223, 0.10513341])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(Xtrain)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 0.00046476606258046954\n",
      "49 0.0014513806842925234\n"
     ]
    }
   ],
   "source": [
    "rez=np.zeros(100)\n",
    "for x in range(2):\n",
    "    a = np.random.choice(3420,20+30*x,replace=False)\n",
    "    Xtrainb=Xtrain[a]\n",
    "    Ytrainb=Ytrain[a]\n",
    "    model = EvalNet(dropout_rate=0.1)\n",
    "    model = model.float().cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), weight_decay=0)\n",
    "    criterion = F.mse_loss\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    inference_dataset = csvDataset(Xtest,Ytest,transform= ToTensor())\n",
    "    inference_loader = torch.utils.data.DataLoader(inference_dataset,batch_size=Xtest.shape[0], shuffle=False)\n",
    "    \n",
    "    file_dataset = csvDataset(Xtrainb,Ytrainb,transform= ToTensor())\n",
    "    final_loader = torch.utils.data.DataLoader(file_dataset,batch_size=1 ,shuffle=False)\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.float().cuda()\n",
    "\n",
    "    criterion = F.mse_loss\n",
    "    model, error,ep= train_model_cc_fast(model, final_loader, criterion, optimizer,Xtrain.shape[0], num_epochs=50)\n",
    "    print(ep,error)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in inference_loader:\n",
    "            inputs = i['data']\n",
    "            labels = i['label']\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            out = model.forward(inputs)\n",
    "            pred = (out.cpu().numpy())*1.\n",
    "            labels = (labels.cpu().numpy())*1.\n",
    "\n",
    "    rez[x]=np.sum((pred-labels)**2)/Xtest.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7f8c030e80>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(2)/10,rez[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizer_ import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " inference_loader = torch.utils.data.DataLoader(inference_dataset,batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam_grad_length(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.64 64.64 64.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L 3\n",
      "5 ()\n"
     ]
    }
   ],
   "source": [
    "for i in (inference_loader):\n",
    "    inputs = i['data']\n",
    "    labels = i['label']\n",
    "    if use_cuda:\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    def closure():\n",
    "            optimizer.zero_grad()\n",
    "            logits = model.forward(inputs)\n",
    "            loss = criterion(logits, labels)\n",
    "            return loss\n",
    "    k,G2,A2 = optimizer.step(closure)\n",
    "    print(len(ggn),ggn[0].cpu().numpy().shape)\n",
    "    break        \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7801, 4.0970, 0.5750, 1.4319, 3.0890], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(6):\n",
    "    print(ggn[i].cpu().numpy().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2.shape,G2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.einsum('ij, ik->jk', G2, A2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2.sum(1).shape,G2.sum(1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2.sum(1).mul(G2.sum(1)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, l in model.named_parameters() :\n",
    "    print(x,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), weight_decay=0,lr = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.train(True)\n",
    "for i in inference_loader:\n",
    "    inputs = i['data']\n",
    "    labels = i['label']\n",
    "    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    if isinstance(optimizer, VOGN):\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            logits = model.forward(inputs)\n",
    "            loss = criterion(logits, labels)\n",
    "            return loss\n",
    "    else:\n",
    "        def closure_():\n",
    "            optimizer.zero_grad()\n",
    "            logits = model.forward(inputs)\n",
    "            loss = criterion(logits, labels)\n",
    "            print('loss',loss)\n",
    "            return loss\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,l in model.named_parameters() :\n",
    "    l.register_hook(lambda grad: print(grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.2548, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = optimizer.step(closure_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of f1.weight w.r.t to Loss: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "Gradient of f1.bias w.r.t to Loss: 0.0\n",
      "Gradient of f2.weight w.r.t to Loss: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0')\n",
      "Gradient of f2.bias w.r.t to Loss: 0.0\n",
      "Gradient of f3.weight w.r.t to Loss: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0')\n",
      "Gradient of f3.bias w.r.t to Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "for x, l in model.named_parameters() :\n",
    "    gradient, *_ = l.grad.data\n",
    "    print(f\"Gradient of {x} w.r.t to Loss: {gradient}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0066, -0.0139,  0.0017,  0.0263,  0.0419, -0.0261, -0.0108],\n",
      "       device='cuda:0')\n",
      "tensor([[ 2.5246e-03,  3.2181e-03, -4.6314e-03, -1.6557e-03, -1.9745e-03,\n",
      "          1.4183e-03,  1.0159e-03,  2.3072e-04,  5.2777e-03,  6.6243e-05,\n",
      "         -1.0753e-03,  8.9270e-03,  5.7891e-03,  1.7384e-03,  3.4144e-03,\n",
      "          6.7891e-04,  1.3958e-03,  1.0001e-03, -1.1065e-03,  1.1886e-03,\n",
      "         -4.4210e-05, -3.7499e-03,  5.5985e-03, -8.0732e-04,  1.4020e-03,\n",
      "          1.4712e-03,  5.9631e-03,  1.0087e-02, -3.9472e-03,  9.7613e-04,\n",
      "          5.6359e-03,  4.8534e-04,  8.2329e-03, -1.3932e-03, -3.7397e-03,\n",
      "          6.5640e-03,  8.9115e-03,  6.1145e-03,  4.6508e-04,  5.3835e-03,\n",
      "          4.5305e-03,  3.7565e-03,  0.0000e+00,  8.3335e-04, -4.6208e-03,\n",
      "         -2.3061e-03, -4.8867e-03,  3.7877e-03, -7.6795e-04,  2.7540e-03,\n",
      "          1.0398e-03,  5.5943e-03, -5.0080e-05,  6.6128e-03, -2.4679e-05,\n",
      "         -3.0989e-03,  3.6905e-03,  6.6931e-03, -1.2903e-03,  9.0220e-03,\n",
      "          2.3391e-03,  1.9541e-05, -3.7703e-03,  3.8377e-03],\n",
      "        [-8.7472e-03, -3.3775e-03,  3.2105e-03, -7.4173e-03, -9.1002e-03,\n",
      "         -7.4974e-03, -6.1096e-03, -1.0640e-02,  8.0250e-04, -4.5464e-05,\n",
      "          3.2568e-03, -3.6791e-03, -2.7786e-04, -5.9804e-03, -3.7434e-03,\n",
      "         -1.0383e-03, -1.0154e-03, -5.4606e-03, -2.7324e-03, -1.2922e-02,\n",
      "          1.5826e-05,  1.1477e-03, -4.9003e-03,  1.3918e-03, -1.4336e-02,\n",
      "         -8.6079e-03, -8.9220e-03, -1.0375e-02,  3.7272e-03,  9.4088e-04,\n",
      "         -3.4423e-03,  1.2693e-03, -1.8714e-03, -1.1698e-03,  3.8109e-03,\n",
      "         -5.0789e-03, -3.9415e-03, -9.9530e-03,  1.4123e-03, -3.9030e-03,\n",
      "         -9.0089e-03,  1.0053e-03,  0.0000e+00, -1.5808e-03, -1.5537e-03,\n",
      "         -3.5602e-03, -5.0864e-03,  3.2339e-03, -4.2472e-03, -6.7373e-04,\n",
      "         -1.0428e-02, -9.8055e-04, -1.1914e-02, -3.1707e-03, -1.5357e-03,\n",
      "         -2.1606e-03, -1.4333e-02, -5.0341e-03, -3.0286e-03, -8.8006e-03,\n",
      "         -1.3724e-04,  1.0365e-05, -2.7339e-03,  1.0015e-03],\n",
      "        [-7.6593e-03,  1.2286e-02,  8.6767e-03, -4.7091e-03, -8.9038e-03,\n",
      "         -9.4492e-03, -6.0262e-04, -4.6950e-03,  6.1359e-03, -4.3163e-05,\n",
      "          1.3756e-03,  9.1762e-03,  2.5419e-04, -2.9149e-03, -2.4150e-03,\n",
      "         -3.4221e-03,  3.5933e-04,  1.9453e-03, -9.6076e-04, -9.1058e-03,\n",
      "         -4.4566e-05,  1.2182e-03,  7.5294e-03,  9.3195e-03, -1.4013e-02,\n",
      "         -2.8120e-03,  5.2064e-03,  3.6860e-03, -3.3595e-04,  5.1822e-03,\n",
      "          2.1436e-03,  7.1063e-03,  1.4845e-02,  2.1484e-03, -4.3577e-03,\n",
      "          7.4328e-03, -3.5109e-04, -2.3669e-03,  8.0152e-03, -3.7058e-03,\n",
      "         -2.8723e-03,  1.0871e-02,  0.0000e+00,  1.0603e-02, -2.1621e-03,\n",
      "          5.1950e-03, -3.8940e-03, -4.8977e-03,  8.5278e-05,  3.4580e-03,\n",
      "         -7.0189e-03, -9.8142e-04, -8.8863e-03,  2.3261e-03,  2.4787e-03,\n",
      "          6.3575e-03,  4.6077e-04,  1.7974e-03,  4.0571e-03,  3.2301e-03,\n",
      "          7.8243e-03,  4.8800e-05,  2.8989e-03,  1.1610e-03],\n",
      "        [ 8.3500e-03,  6.7354e-03,  6.8775e-04,  7.5301e-03,  7.6161e-03,\n",
      "          8.0823e-03,  6.3092e-03,  1.0282e-02, -3.3136e-03,  1.0306e-04,\n",
      "          2.9710e-04,  5.5941e-03,  1.6147e-02,  5.3847e-03,  2.4227e-03,\n",
      "          5.1842e-03,  6.8441e-04,  9.9622e-03,  3.1123e-03,  1.1818e-02,\n",
      "         -6.7871e-05,  4.2560e-03,  5.8600e-03,  2.9157e-03,  1.4652e-02,\n",
      "          1.4871e-02,  9.2595e-03,  1.3915e-02,  3.9212e-03,  6.2251e-03,\n",
      "          7.0646e-03, -2.8192e-04,  3.4790e-05,  1.0067e-02,  6.5239e-03,\n",
      "          1.2479e-02,  6.2478e-03,  9.7849e-03,  3.6209e-03,  4.9883e-03,\n",
      "          1.1925e-02,  2.6648e-03,  0.0000e+00, -1.6296e-03,  3.0735e-03,\n",
      "          2.9601e-04,  5.1135e-03,  4.3639e-03,  5.0678e-03,  9.1956e-04,\n",
      "          1.1496e-02,  2.4340e-03,  1.1439e-02,  4.5305e-03,  9.9529e-03,\n",
      "          3.8578e-03,  9.2056e-03,  1.1945e-02,  3.0199e-03,  1.1709e-02,\n",
      "          2.3140e-04,  1.2518e-06,  2.4887e-03,  1.0825e-02],\n",
      "        [ 1.6615e-02,  1.5360e-02,  4.0366e-02,  1.2767e-02,  1.8535e-02,\n",
      "          1.2743e-02,  9.4891e-03,  1.3894e-02, -7.7010e-04, -1.7148e-05,\n",
      "          2.0885e-02, -2.2548e-03,  9.3410e-03,  4.3057e-03,  9.6370e-04,\n",
      "          1.8440e-02,  1.8896e-02, -2.6064e-03,  1.6751e-02,  2.2993e-02,\n",
      "          2.3828e-04,  2.1653e-02,  7.1935e-03,  2.0624e-02,  2.3720e-02,\n",
      "          3.7913e-02,  4.3171e-03,  1.7953e-02,  3.6188e-02,  4.5850e-03,\n",
      "          2.7445e-04,  6.5967e-04,  9.2937e-03,  1.3572e-02,  3.0328e-02,\n",
      "         -9.4515e-03,  1.7263e-02,  3.1089e-03,  1.4249e-02,  7.5083e-03,\n",
      "          6.5948e-03,  3.4523e-03,  0.0000e+00,  9.0163e-03,  3.7250e-02,\n",
      "          2.1601e-02,  3.3014e-02,  9.9439e-03,  7.6936e-03, -2.3523e-03,\n",
      "          2.1742e-02,  7.6326e-03,  2.1310e-02, -3.7135e-03,  1.3696e-02,\n",
      "          2.1297e-02,  1.0776e-02,  4.5898e-03,  1.5144e-02,  3.2900e-03,\n",
      "          1.7327e-02, -8.3217e-06,  2.9162e-02,  5.2587e-03],\n",
      "        [-1.2596e-02, -1.5548e-02, -1.3947e-02, -1.8566e-04,  6.7606e-03,\n",
      "         -8.2784e-03, -7.3971e-03,  1.0119e-02,  1.7310e-03,  7.6346e-05,\n",
      "         -7.6074e-03, -3.1370e-03, -1.3739e-03, -1.2287e-03,  1.7043e-03,\n",
      "         -2.1210e-02, -3.4616e-03,  6.3304e-03, -3.7624e-03, -7.7231e-03,\n",
      "          4.0065e-05, -1.3509e-02, -2.5352e-03, -1.4973e-02, -4.2005e-03,\n",
      "         -1.9964e-02, -2.7140e-03, -5.4618e-03, -1.9565e-02, -1.2643e-02,\n",
      "         -1.6276e-03, -2.5931e-03, -1.2531e-02, -2.1391e-02, -2.7855e-02,\n",
      "          3.9528e-03, -1.2527e-02,  4.6202e-03, -2.1169e-02, -9.4628e-03,\n",
      "          8.0295e-04, -1.0173e-02,  0.0000e+00, -1.0185e-02, -9.2836e-03,\n",
      "         -1.9071e-03, -2.0138e-02, -3.0374e-03,  7.1493e-03, -5.3014e-04,\n",
      "          5.9359e-03, -1.4224e-02,  8.8088e-03, -2.0649e-03, -1.2931e-02,\n",
      "         -1.2242e-02,  3.9223e-03, -3.4813e-03, -1.6512e-02, -2.3014e-03,\n",
      "         -8.7492e-03, -5.0468e-05, -3.5373e-03,  6.7687e-04],\n",
      "        [-1.3795e-02,  5.9897e-04,  9.8782e-03, -5.9236e-03, -9.8884e-03,\n",
      "         -1.6343e-02, -4.9153e-03, -1.7025e-02, -3.3243e-03, -8.1973e-05,\n",
      "          2.9123e-03, -9.4852e-03, -9.0892e-03, -9.7508e-03, -7.6814e-03,\n",
      "          5.5326e-03,  8.9475e-04, -2.0676e-02,  3.0224e-03, -1.4672e-02,\n",
      "          8.1547e-05,  7.7380e-03, -5.7179e-03,  3.5645e-03, -1.6675e-02,\n",
      "         -7.4637e-04, -1.4320e-02, -1.1682e-02,  9.4539e-03,  1.0192e-03,\n",
      "         -1.0583e-02,  1.7522e-03,  3.4055e-04,  3.4589e-03,  9.9012e-03,\n",
      "         -1.0662e-02, -4.9013e-03, -1.8803e-02,  6.1785e-03, -1.2661e-02,\n",
      "         -2.2648e-02, -1.8812e-03,  0.0000e+00,  5.3229e-03,  4.3006e-03,\n",
      "          4.6482e-03,  1.2078e-02, -1.8392e-03, -1.0892e-02, -2.1884e-03,\n",
      "         -6.3798e-03,  3.6432e-03, -1.3304e-02, -8.3298e-03,  2.6718e-03,\n",
      "          5.4531e-03, -2.2973e-02, -1.1225e-02,  6.9775e-03, -1.4485e-02,\n",
      "          4.4591e-03, -2.5478e-06,  4.5243e-03, -9.7009e-03]], device='cuda:0')\n",
      "tensor([-3.4105e-04,  5.2719e-03,  2.3672e-03, -1.8932e-03, -7.2289e-03,\n",
      "        -3.0150e-03, -9.8006e-04, -1.3234e-04,  4.1836e-04,  1.0544e-04,\n",
      "        -6.4397e-03, -2.9635e-03, -5.8883e-03, -1.8133e-03, -1.9653e-03,\n",
      "        -2.5667e-03, -2.3001e-03, -5.7732e-03, -1.6756e-03,  1.8062e-03,\n",
      "        -3.0321e-04, -7.7933e-03,  1.6843e-03,  3.8594e-03, -3.3979e-04,\n",
      "         8.7896e-03, -2.1815e-03,  3.2590e-03, -5.2028e-03, -3.3573e-03,\n",
      "        -4.1288e-03,  2.1911e-03,  1.6663e-03, -4.1820e-03, -7.5490e-03,\n",
      "        -4.1572e-03,  4.4836e-03, -4.1694e-03, -2.1007e-03,  6.3478e-06,\n",
      "        -8.5259e-03,  3.2795e-03,  0.0000e+00, -1.6164e-03,  2.7008e-03,\n",
      "         2.3758e-03,  8.8151e-04, -6.7423e-03, -4.8214e-03, -9.3756e-04,\n",
      "        -7.1323e-03, -2.1168e-03, -6.0661e-03, -1.1147e-03, -9.0006e-03,\n",
      "         5.5574e-03, -1.3994e-03, -7.3328e-03, -1.5264e-03, -3.7889e-03,\n",
      "         1.2452e-03, -1.8247e-05,  4.7723e-03,  1.7775e-03], device='cuda:0')\n",
      "tensor([[ 3.6168e-04, -1.0784e-03,  7.0598e-04,  ...,  9.6115e-04,\n",
      "         -3.3215e-04,  7.6944e-06],\n",
      "        [ 1.1519e-03,  1.5294e-03,  1.3140e-03,  ...,  9.6597e-04,\n",
      "          2.8173e-03,  2.0984e-03],\n",
      "        [ 2.8659e-03, -7.8594e-04,  6.7078e-04,  ..., -7.2517e-04,\n",
      "          2.9401e-03, -1.1855e-03],\n",
      "        ...,\n",
      "        [ 3.1092e-06, -8.5334e-07,  2.3272e-05,  ...,  2.1174e-05,\n",
      "         -4.3222e-06,  2.7983e-05],\n",
      "        [ 2.5204e-03, -1.8246e-03,  1.0710e-03,  ...,  2.1013e-03,\n",
      "          4.5590e-03,  6.5802e-04],\n",
      "        [ 1.2997e-03,  1.1296e-03,  9.1910e-04,  ...,  1.2360e-03,\n",
      "          2.9222e-03, -3.1410e-04]], device='cuda:0')\n",
      "tensor([-1.8285e-03, -7.5469e-03,  2.8567e-03,  8.6548e-04,  2.6606e-03,\n",
      "        -3.9454e-04, -6.2505e-04,  2.7437e-03, -3.0146e-03, -3.8643e-03,\n",
      "         1.9688e-03, -3.3089e-03,  1.3627e-03, -5.1580e-03,  2.3288e-04,\n",
      "         1.5642e-03,  1.9552e-03, -2.9227e-03, -2.2131e-03, -9.7749e-04,\n",
      "         2.0964e-03, -1.7211e-03, -1.8083e-03,  3.0141e-04,  9.8011e-03,\n",
      "        -7.8813e-03,  9.6323e-03, -7.2973e-03,  4.4094e-03, -1.8563e-03,\n",
      "        -7.8965e-04, -1.6646e-03, -5.0077e-03, -4.6597e-03, -2.7849e-03,\n",
      "        -6.0333e-04, -6.8169e-03, -2.7413e-03, -7.3275e-04,  5.1062e-04,\n",
      "         8.5616e-03, -1.5272e-03,  3.4705e-04, -3.6410e-03,  9.2924e-03,\n",
      "         2.9108e-03, -4.7683e-03, -9.3435e-04, -2.6728e-03, -5.2248e-03,\n",
      "         7.9721e-05, -1.0507e-03, -2.1513e-03,  3.0939e-03, -2.1322e-03,\n",
      "        -2.7329e-03, -2.8766e-03, -4.0941e-03,  3.4712e-03, -4.5708e-03,\n",
      "        -3.7959e-03, -2.5022e-03,  1.0283e-03, -2.0696e-04], device='cuda:0')\n",
      "tensor([[-1.1590e-03,  1.3626e-03, -3.7460e-03, -6.2860e-04,  6.4199e-04,\n",
      "         -9.7164e-04,  5.5579e-04,  1.6552e-03, -4.0006e-03],\n",
      "        [ 1.6238e-03, -1.8185e-03,  1.2418e-02, -3.6594e-06, -8.3711e-04,\n",
      "          1.0899e-02, -3.2374e-03,  3.5624e-03,  5.7229e-03],\n",
      "        [ 3.1416e-03,  6.8238e-04, -6.0876e-04,  2.3760e-03, -2.6400e-04,\n",
      "          7.9616e-05, -2.8757e-04, -1.4233e-04, -1.2126e-03],\n",
      "        [ 3.8525e-03,  3.6442e-05,  8.9116e-03,  3.4734e-03, -3.0876e-04,\n",
      "          4.4655e-03,  8.1821e-04, -2.2070e-03,  3.4508e-03],\n",
      "        [-4.5899e-03,  3.2513e-03, -1.9870e-03,  4.1096e-04,  5.0789e-03,\n",
      "         -3.7658e-03,  2.1149e-03, -1.5839e-03,  1.4345e-04],\n",
      "        [-3.0585e-03,  4.4825e-03, -3.6574e-03,  2.8635e-03,  1.8662e-03,\n",
      "         -2.9985e-03,  2.8960e-03, -2.4468e-03,  2.5018e-03],\n",
      "        [-2.8312e-03, -6.3760e-03,  4.3700e-03,  1.9974e-03, -3.2709e-03,\n",
      "          2.0592e-03, -1.0852e-03,  8.8108e-04,  2.0021e-03],\n",
      "        [-8.5085e-03, -7.1068e-03,  3.3428e-04, -5.1614e-03,  4.7466e-04,\n",
      "         -1.1404e-03, -6.8118e-03,  3.4480e-03, -5.9247e-03],\n",
      "        [ 2.0958e-03,  3.1006e-03, -4.0330e-04,  1.4283e-03,  1.7260e-03,\n",
      "         -2.5265e-03,  1.9091e-03, -1.8004e-03,  3.3190e-04],\n",
      "        [-4.5757e-03,  2.0922e-03, -2.3066e-03, -1.0326e-03,  1.2259e-03,\n",
      "         -2.5153e-03,  2.5866e-05,  1.6515e-03, -1.7736e-03],\n",
      "        [-1.2348e-03, -1.8221e-03,  3.4780e-03,  2.1285e-03, -1.6456e-03,\n",
      "          1.2089e-03, -1.3772e-03, -2.3088e-04, -7.6265e-04],\n",
      "        [-2.4146e-03,  4.4804e-04, -6.5949e-03, -1.5874e-03, -1.7871e-03,\n",
      "         -6.1503e-03,  1.4533e-03,  3.5376e-03,  8.0875e-04],\n",
      "        [-7.9906e-03, -9.1477e-03,  5.0893e-03, -3.7307e-03, -3.4865e-04,\n",
      "          1.9398e-03, -6.0099e-03, -2.7946e-04, -9.0263e-03],\n",
      "        [-2.5684e-03, -8.3106e-03, -9.1266e-03, -9.1507e-03, -1.0419e-02,\n",
      "         -1.2098e-03, -3.9328e-03, -3.0855e-03, -9.5006e-03],\n",
      "        [-3.4961e-03, -5.2528e-03,  1.7353e-03, -2.6343e-03, -5.1335e-03,\n",
      "          1.0496e-03, -2.4158e-03,  1.0336e-03, -2.0480e-03],\n",
      "        [-1.6838e-03, -1.4403e-03,  2.9826e-03,  1.0857e-03,  5.9646e-04,\n",
      "          9.0101e-04, -1.4809e-03,  3.0518e-03,  3.1005e-04],\n",
      "        [ 3.3789e-03,  5.5079e-04, -3.1751e-03, -1.0061e-03, -2.4832e-03,\n",
      "         -4.9069e-03,  9.3280e-04,  1.4093e-03,  4.7142e-03],\n",
      "        [ 2.3593e-03, -2.2392e-03,  9.9509e-03, -5.6755e-04, -5.1213e-04,\n",
      "          1.1652e-02,  5.1980e-04,  1.2054e-03,  7.7170e-03],\n",
      "        [ 1.9922e-04,  1.4489e-03, -7.3650e-04, -1.4743e-03,  1.5585e-03,\n",
      "         -2.3407e-03,  6.8980e-05,  2.4071e-03,  2.7189e-03],\n",
      "        [-3.0184e-04,  3.4181e-03,  2.7701e-04,  5.7610e-05,  9.1075e-06,\n",
      "         -2.5129e-03, -1.1411e-03,  2.4510e-03,  4.8649e-03],\n",
      "        [ 2.6286e-03,  3.0803e-03,  4.0346e-03,  3.4067e-03,  1.7800e-03,\n",
      "          1.7470e-03,  1.5882e-03,  4.9976e-04,  4.8359e-03],\n",
      "        [-3.0942e-03, -3.9382e-03, -1.0230e-03, -6.1374e-03, -1.8051e-03,\n",
      "          3.8971e-03, -3.0904e-03,  1.5192e-03, -4.3086e-03],\n",
      "        [-1.4896e-03, -1.2446e-03, -1.0301e-03, -2.4204e-04,  4.4458e-04,\n",
      "          1.0966e-03, -2.0129e-03,  7.3327e-04, -3.2819e-03],\n",
      "        [-4.9216e-04,  8.4288e-04,  3.4589e-03, -2.2673e-03,  3.8399e-03,\n",
      "          3.5053e-03,  1.1957e-03,  2.9800e-03,  2.6853e-04],\n",
      "        [-5.6741e-03,  1.9051e-03,  3.4009e-03,  4.0951e-03,  2.5892e-03,\n",
      "         -2.4115e-03,  4.3383e-03, -4.8805e-03,  5.8154e-03],\n",
      "        [ 6.7021e-03, -5.8805e-03,  4.2259e-03,  6.3318e-04, -3.0135e-03,\n",
      "          8.3211e-03, -1.7622e-03,  5.8905e-03,  5.9215e-04],\n",
      "        [ 6.8988e-03,  6.8776e-03,  3.9038e-03,  1.0383e-03,  8.6837e-03,\n",
      "         -1.6721e-03,  4.0641e-03, -3.2742e-03,  9.5631e-03],\n",
      "        [ 2.8790e-03,  6.4785e-03,  5.6874e-03,  1.0148e-02, -1.6454e-03,\n",
      "          9.9889e-04,  3.4118e-03, -3.4251e-04,  8.4230e-03],\n",
      "        [-4.0613e-03,  2.2036e-05,  2.5712e-04,  2.3561e-03,  4.9246e-03,\n",
      "          8.7935e-04, -1.2197e-03, -3.0007e-03, -7.1581e-04],\n",
      "        [ 2.2095e-03,  2.2922e-03,  9.5889e-03,  4.1563e-03, -1.6012e-03,\n",
      "          1.9669e-03,  2.1359e-03,  3.8833e-04,  1.1918e-02],\n",
      "        [ 2.1590e-03,  1.3470e-04, -7.7160e-03, -4.0166e-03,  2.2185e-03,\n",
      "          9.7081e-04, -1.0265e-03,  8.5288e-04, -1.6170e-03],\n",
      "        [ 3.1627e-03,  6.6358e-03, -4.2064e-03, -2.6449e-04,  5.1142e-03,\n",
      "         -5.2688e-03,  2.2784e-03, -7.7812e-04,  1.1990e-03],\n",
      "        [-9.1946e-04, -1.9899e-03,  1.6571e-03,  6.7395e-03, -1.4337e-03,\n",
      "          5.2581e-03, -2.4825e-03,  6.9123e-03, -4.7238e-03],\n",
      "        [-3.4092e-04, -4.5829e-03,  9.3553e-03,  3.7180e-03, -3.0599e-03,\n",
      "          4.7540e-03, -1.8295e-03,  1.9146e-03,  2.1778e-03],\n",
      "        [-5.0055e-03, -8.1980e-03,  3.1617e-03, -7.0426e-03, -5.1278e-03,\n",
      "          3.8720e-03, -5.2750e-03,  1.2714e-03, -5.0085e-03],\n",
      "        [ 3.9357e-03, -6.8339e-03,  1.2081e-03,  1.8096e-03, -3.5623e-03,\n",
      "          2.8695e-03, -1.6187e-03, -4.7928e-04, -2.7676e-03],\n",
      "        [-2.3488e-03,  6.7970e-04,  1.4378e-02,  1.7469e-03,  1.6503e-04,\n",
      "          7.9652e-03, -3.6767e-04,  3.4170e-03,  9.3891e-03],\n",
      "        [-4.3097e-03, -2.6030e-03, -2.6972e-03, -8.6916e-03, -1.4527e-03,\n",
      "          3.6143e-03, -6.4442e-03,  4.2929e-03, -6.5884e-03],\n",
      "        [ 5.0726e-04, -1.2748e-03,  5.0283e-03,  3.4831e-03, -1.0959e-03,\n",
      "          2.8803e-03,  2.6309e-04,  9.1892e-04,  2.0423e-03],\n",
      "        [ 9.2732e-04,  1.8488e-03, -2.5713e-03,  1.6121e-03, -1.0980e-03,\n",
      "         -1.8765e-03,  2.6627e-03, -5.2559e-03, -1.2668e-03],\n",
      "        [-5.3279e-03, -3.1192e-03,  6.2011e-03,  7.1490e-03,  8.2757e-04,\n",
      "          1.7702e-03,  1.6709e-04, -1.4083e-03,  1.1457e-04],\n",
      "        [-6.0393e-04,  3.7950e-03,  6.1567e-04, -2.5549e-04,  3.4671e-03,\n",
      "         -2.3900e-03,  1.0244e-03,  3.2529e-05,  6.8342e-04],\n",
      "        [ 2.0506e-03,  3.0940e-03,  3.0900e-03,  5.0619e-03,  2.7850e-03,\n",
      "          1.7409e-03,  1.3637e-03,  3.9458e-05,  6.2622e-03],\n",
      "        [-7.4100e-04,  1.7291e-03, -6.7294e-03,  1.5589e-03,  1.4773e-03,\n",
      "         -4.7036e-03,  7.3254e-04, -2.9510e-04, -3.7521e-03],\n",
      "        [ 6.4171e-03,  6.3209e-03,  1.4238e-03, -2.2123e-03,  6.8184e-04,\n",
      "         -5.5905e-04,  2.7763e-03, -2.5353e-03,  1.0469e-02],\n",
      "        [-1.7357e-03,  1.0531e-03,  5.3917e-03,  4.9206e-03, -9.1423e-04,\n",
      "         -2.6973e-03, -5.4155e-04, -3.0222e-03,  4.5839e-03],\n",
      "        [ 4.9281e-03,  3.3973e-03,  6.0271e-03,  1.1044e-02,  5.2822e-04,\n",
      "          3.2256e-03,  1.3387e-03, -1.9389e-03,  1.1169e-02],\n",
      "        [-1.1610e-03, -4.2056e-03, -2.9472e-03, -3.5278e-03, -1.0870e-03,\n",
      "          1.6357e-03, -4.0154e-03,  3.9252e-04, -5.9497e-03],\n",
      "        [-1.1460e-03, -2.8618e-03, -3.8428e-03, -2.6217e-03, -4.5278e-03,\n",
      "         -2.8081e-03,  6.0099e-04, -1.5712e-03, -6.7300e-04],\n",
      "        [ 5.9832e-03,  6.1436e-04,  4.8637e-03,  1.7615e-04,  1.8858e-03,\n",
      "          5.5648e-03, -3.7281e-04,  1.5677e-03,  6.0380e-03],\n",
      "        [-5.0358e-04, -1.0312e-03,  1.7104e-03, -1.9065e-04,  1.4190e-03,\n",
      "          8.7229e-04, -1.3913e-03,  1.2484e-03,  1.2713e-03],\n",
      "        [ 1.7719e-03, -1.7019e-03, -1.9800e-03,  1.3861e-03, -1.5409e-03,\n",
      "          2.9210e-03, -1.8057e-03,  8.0727e-04, -4.2482e-03],\n",
      "        [ 3.2998e-03,  2.9301e-03,  3.0768e-04,  2.0861e-03,  3.1351e-03,\n",
      "         -8.8676e-04,  2.5174e-03, -8.7742e-04,  2.5543e-03],\n",
      "        [ 7.0342e-03,  9.8812e-03,  1.9361e-03,  1.0077e-02,  1.8008e-03,\n",
      "         -1.9254e-03,  3.8474e-03, -1.4727e-03,  1.0839e-02],\n",
      "        [ 1.0091e-02, -1.6126e-03, -9.5806e-03, -4.7911e-03, -3.5819e-03,\n",
      "         -4.3504e-03,  1.7570e-03, -4.1839e-04,  2.4742e-03],\n",
      "        [ 4.4576e-05,  2.1762e-03,  1.3530e-04, -7.6963e-04,  3.4956e-03,\n",
      "          2.8990e-03, -5.6197e-04, -1.3314e-03,  4.0219e-04],\n",
      "        [-7.6066e-04, -5.0388e-04,  2.9106e-03,  6.1873e-04, -1.3499e-03,\n",
      "          7.7533e-04, -8.5136e-04,  1.7697e-03,  4.8150e-03],\n",
      "        [ 4.1897e-03, -3.3786e-03,  4.2326e-03,  2.3763e-03, -2.7344e-03,\n",
      "          4.8981e-03,  3.2014e-04,  5.1703e-03,  5.4126e-03],\n",
      "        [-4.8365e-03, -4.8919e-03,  1.4666e-04, -2.1335e-03,  1.5438e-03,\n",
      "          3.0301e-03, -1.3500e-03,  1.8019e-03, -2.1096e-03],\n",
      "        [-5.7037e-03, -4.9732e-03, -6.7360e-03, -4.4709e-03, -3.7375e-03,\n",
      "          3.3789e-03, -5.4461e-03,  5.8346e-03, -7.1704e-03],\n",
      "        [ 1.1084e-03, -9.6111e-04, -3.4891e-03, -4.8193e-03, -4.3440e-03,\n",
      "         -6.7049e-03,  8.4399e-04,  2.9808e-03, -1.7372e-03],\n",
      "        [-9.0583e-03, -3.4148e-03, -9.7506e-03, -7.5914e-04, -6.5835e-04,\n",
      "         -6.0134e-04, -1.1573e-03,  1.0874e-02, -1.0423e-03],\n",
      "        [ 7.1046e-03, -5.3502e-03, -8.2500e-03, -2.1129e-03, -6.5707e-03,\n",
      "         -4.4478e-03,  3.9585e-03, -2.4257e-03,  1.3215e-04],\n",
      "        [ 2.2405e-03,  5.4788e-03,  4.4875e-03,  1.0216e-03,  2.2047e-03,\n",
      "          4.3481e-03,  1.6380e-03,  7.4100e-04,  2.6322e-03]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of f1.weight w.r.t to Loss: tensor([-0.0012,  0.0014, -0.0037, -0.0006,  0.0006, -0.0010,  0.0006,  0.0017,\n",
      "        -0.0040], device='cuda:0')\n",
      "Gradient of f1.bias w.r.t to Loss: -0.0018285131081938744\n",
      "Gradient of f2.weight w.r.t to Loss: tensor([ 3.6168e-04, -1.0784e-03,  7.0598e-04, -5.2577e-06, -1.2583e-03,\n",
      "        -8.6666e-04, -1.7687e-04, -1.1936e-04, -3.9483e-05,  6.7704e-04,\n",
      "        -3.4847e-05, -2.7146e-04,  5.0944e-04,  7.5217e-04,  3.5699e-05,\n",
      "        -1.1857e-03,  1.7030e-04,  6.4953e-04, -1.0684e-03, -6.2700e-04,\n",
      "        -1.6359e-04,  4.5777e-04,  4.7952e-05, -6.4822e-04, -1.2035e-03,\n",
      "        -6.2652e-04, -1.9162e-04, -1.2787e-03,  2.9772e-04,  3.6642e-04,\n",
      "         5.5618e-04,  2.0474e-05,  1.0704e-04, -4.0733e-04,  1.9050e-03,\n",
      "        -3.6496e-04, -1.3064e-03,  3.4986e-04,  2.5863e-04,  9.1161e-04,\n",
      "        -5.3867e-04, -1.9272e-04, -4.9081e-04, -4.4351e-04, -1.1025e-03,\n",
      "         7.7164e-05, -4.4906e-04,  7.8675e-04,  1.0131e-04,  8.4868e-04,\n",
      "        -9.2307e-04,  4.1121e-04, -6.7983e-04,  5.6894e-04, -7.9306e-05,\n",
      "        -5.4650e-04,  9.1290e-05, -4.2761e-04, -3.6033e-04,  1.1023e-03,\n",
      "        -9.4010e-04,  9.6115e-04, -3.3215e-04,  7.6944e-06], device='cuda:0')\n",
      "Gradient of f2.bias w.r.t to Loss: -0.00034104997757822275\n",
      "Gradient of f3.weight w.r.t to Loss: tensor([ 2.5246e-03,  3.2181e-03, -4.6314e-03, -1.6557e-03, -1.9745e-03,\n",
      "         1.4183e-03,  1.0159e-03,  2.3072e-04,  5.2777e-03,  6.6243e-05,\n",
      "        -1.0753e-03,  8.9270e-03,  5.7891e-03,  1.7384e-03,  3.4144e-03,\n",
      "         6.7891e-04,  1.3958e-03,  1.0001e-03, -1.1065e-03,  1.1886e-03,\n",
      "        -4.4210e-05, -3.7499e-03,  5.5985e-03, -8.0732e-04,  1.4020e-03,\n",
      "         1.4712e-03,  5.9631e-03,  1.0087e-02, -3.9472e-03,  9.7613e-04,\n",
      "         5.6359e-03,  4.8534e-04,  8.2329e-03, -1.3932e-03, -3.7397e-03,\n",
      "         6.5640e-03,  8.9115e-03,  6.1145e-03,  4.6508e-04,  5.3835e-03,\n",
      "         4.5305e-03,  3.7565e-03,  0.0000e+00,  8.3335e-04, -4.6208e-03,\n",
      "        -2.3061e-03, -4.8867e-03,  3.7877e-03, -7.6795e-04,  2.7540e-03,\n",
      "         1.0398e-03,  5.5943e-03, -5.0080e-05,  6.6128e-03, -2.4679e-05,\n",
      "        -3.0989e-03,  3.6905e-03,  6.6931e-03, -1.2903e-03,  9.0220e-03,\n",
      "         2.3391e-03,  1.9541e-05, -3.7703e-03,  3.8377e-03], device='cuda:0')\n",
      "Gradient of f3.bias w.r.t to Loss: 0.006602494046092033\n",
      "sum 0.2626458933809772\n"
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "for x, l in model.named_parameters() :\n",
    "    gradient, *_ = l.grad.data\n",
    "    k+=np.sum(np.abs(gradient.cpu().numpy()))\n",
    "    print(f\"Gradient of {x} w.r.t to Loss: {gradient}\")\n",
    "print('sum',k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, l in model.named_parameters() :\n",
    "    print(x,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random(x):\n",
    "    a,b,c = x.shape\n",
    "    return np.mean(np.std(x,axis=0),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10, 15)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.rand(100,10,15)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.transpose(0, 2, 1)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(a,axis=(1,2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
